{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import logging\n",
    "from typing import Any, Tuple, Dict, List, Iterable\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from allennlp.data.dataset_readers.dataset_reader import DatasetReader\n",
    "from allennlp.data.fields import Field, LabelField, TextField, ListField, SequenceLabelField\n",
    "from allennlp.data.instance import Instance\n",
    "from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer, PretrainedBertIndexer\n",
    "from allennlp.data.tokenizers import Token, Tokenizer, WordTokenizer, PretrainedTransformerTokenizer\n",
    "from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import Embedding, PretrainedBertEmbedder\n",
    "from allennlp.modules.seq2vec_encoders import BertPooler\n",
    "\n",
    "from allennlp.modules import Seq2VecEncoder, Seq2SeqEncoder\n",
    "from allennlp.training.metrics import CategoricalAccuracy, F1Measure\n",
    "from allennlp.nn.util import get_text_field_mask, sequence_cross_entropy_with_logits\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "\n",
    "from allennlp.training.trainer import Trainer\n",
    "from allennlp.data.iterators import BucketIterator\n",
    "from allennlp.common import Params\n",
    "from allennlp.nn import util\n",
    "from datetime import date, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from irc_chat_reader import ChatReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_indexers = {\"tokens\": SingleIdTokenIndexer()}\n",
    "\n",
    "tokenizer_cfg = Params({\"word_splitter\": {\"language\": \"en\"}})\n",
    "\n",
    "word_tokenizer = Tokenizer.from_params(tokenizer_cfg)\n",
    "\n",
    "reader = ChatReader(\n",
    "    tokenizer=word_tokenizer,\n",
    "    token_indexers=token_indexers,\n",
    "    raw = True,\n",
    "    sub_sequence = 10,\n",
    "    loop = True,\n",
    "    #clip = 200\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "67415it [00:36, 1855.37it/s]\n"
     ]
    }
   ],
   "source": [
    "train_instances = reader.read(\"../data/train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2497it [00:01, 2169.79it/s]\n"
     ]
    }
   ],
   "source": [
    "dev_instances = reader.read(\"../data/dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69912/69912 [00:05<00:00, 13943.42it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocabulary.from_instances(train_instances+dev_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sdelecra/anaconda3/envs/allennlp/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "400000it [00:02, 190785.53it/s]\n"
     ]
    }
   ],
   "source": [
    "input_size = 300\n",
    "\n",
    "turn_encoder_cfg = Params({\"type\":\"gru\",'input_size': input_size, 'hidden_size': 100, 'num_layers': 1,\n",
    "                      'dropout': 0.25, 'bidirectional': True\n",
    "})\n",
    "#can be changed dynamically encoder_cfg[\"type\"] = \"lstm\"\n",
    "# warning: if bidirectional, state output dimension is hidden_size x 2 \n",
    "\n",
    "turn_encoder = Seq2VecEncoder.from_params(turn_encoder_cfg)\n",
    "turn_encoder.hidden_size = turn_encoder_cfg[\"hidden_size\"]*(1+turn_encoder_cfg[\"bidirectional\"])\n",
    "\n",
    "\n",
    "\n",
    "turn_feature_size = 1\n",
    "\n",
    "chat_encoder_cfg = Params({\"type\":\"gru\",'input_size': turn_encoder.hidden_size, 'hidden_size': 100, 'num_layers': 3,\n",
    "                  'dropout': 0.25, 'bidirectional': False\n",
    "})\n",
    "chat_encoder = Seq2SeqEncoder.from_params(chat_encoder_cfg)\n",
    "chat_encoder.hidden_size = chat_encoder_cfg[\"hidden_size\"]\n",
    "\n",
    "glove_dim, glove_version = input_size, \"../data/glove-ubuntu.txt\"\n",
    "glove_text_field_embedder = Embedding.from_params(vocab,Params({\"pretrained_file\": glove_version,\n",
    "                                                          \"embedding_dim\": glove_dim,\n",
    "                                                          \"trainable\": True\n",
    "}))\n",
    "    \n",
    "\n",
    "#token_embedding = Embedding(num_embeddings=vocab.get_vocab_size('tokens'),\n",
    "#                        embedding_dim=300)\n",
    "token_embedding = glove_text_field_embedder \n",
    "word_embeddings = BasicTextFieldEmbedder({\"tokens\": token_embedding})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_encoder_cfg =  Params({\n",
    "            \"type\": \"stacked_bidirectional_lstm\",\n",
    "            \"hidden_size\": 400,\n",
    "            \"input_size\": 200,\n",
    "            \"num_layers\": 3,\n",
    "            \"recurrent_dropout_probability\": 0.3,\n",
    "            \"use_highway\": True\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.models import Model\n",
    "from typing import Dict, List, Iterable\n",
    "from allennlp.modules import TimeDistributed\n",
    "from allennlp.nn.util import get_text_field_mask, sequence_cross_entropy_with_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.models import Model\n",
    "from allennlp.common.checks import check_dimensions_match, ConfigurationError\n",
    "from allennlp.data import Vocabulary\n",
    "from allennlp.modules import Seq2SeqEncoder, TextFieldEmbedder, Embedding, InputVariationalDropout\n",
    "from allennlp.modules.matrix_attention.bilinear_matrix_attention import BilinearMatrixAttention\n",
    "from allennlp.modules.matrix_attention.dot_product_matrix_attention import DotProductMatrixAttention\n",
    "from allennlp.modules.matrix_attention.linear_matrix_attention import LinearMatrixAttention\n",
    "\n",
    "from allennlp.modules import FeedForward\n",
    "from allennlp.models.model import Model\n",
    "from allennlp.nn import InitializerApplicator, Activation\n",
    "from allennlp.nn.activations import Activation\n",
    "from allennlp.nn.util import add_positional_features\n",
    "\n",
    "\n",
    "#???? TODO from allennlp.nn.util import min_value_of_dtype -> only allennlp >= 1.0\n",
    "def min_value_of_dtype(dtype: torch.dtype):\n",
    "    \"\"\"\n",
    "    Returns the minimum value of a given PyTorch data type. Does not allow torch.bool.\n",
    "    \"\"\"\n",
    "    return info_value_of_dtype(dtype).min\n",
    "def info_value_of_dtype(dtype: torch.dtype):\n",
    "    \"\"\"\n",
    "    Returns the `finfo` or `iinfo` object of a given PyTorch data type. Does not allow torch.bool.\n",
    "    \"\"\"\n",
    "    if dtype == torch.bool:\n",
    "        raise TypeError(\"Does not support torch.bool\")\n",
    "    elif dtype.is_floating_point:\n",
    "        return torch.finfo(dtype)\n",
    "    else:\n",
    "        return torch.iinfo(dtype)\n",
    "\n",
    "# utility for max decoding. should be a better way but...\n",
    "# should also not modify the original tensor ?\n",
    "def force_max(t):\n",
    "    \"\"\"set all values of a tensor (batch,length,length) to zero if not maximum (on a given line)\"\"\"\n",
    "    dims = t.size()\n",
    "    b,_ = t.max(axis=2)\n",
    "    bb = b.repeat((1,dims[1]))\n",
    "    bb = torch.reshape(bb,(dims[0],dims[1],dims[1])).transpose(1,2)\n",
    "    #print(bb)\n",
    "    t[t<bb]=0\n",
    "    return t\n",
    "    \n",
    "    \n",
    "\n",
    "from allennlp.nn.util import get_text_field_mask\n",
    "from allennlp.nn.util import get_lengths_from_binary_sequence_mask\n",
    "from allennlp.training.metrics import F1Measure\n",
    "\n",
    "import copy\n",
    "from overrides import overrides\n",
    "import torch\n",
    "from torch.nn.modules import Dropout\n",
    "from torch.nn.modules.linear import Linear\n",
    "import numpy\n",
    "import pandas as pds\n",
    "\n",
    "class ChatGraphParser(Model):\n",
    "    \"\"\"\n",
    "    A Parser for arbitrary graph structures.\n",
    "\n",
    "    Registered as a `Model` with name \"graph_parser\".\n",
    "\n",
    "    # Parameters\n",
    "\n",
    "    vocab : `Vocabulary`, required\n",
    "        A Vocabulary, required in order to compute sizes for input/output projections.\n",
    "    text_field_embedder : `TextFieldEmbedder`, required\n",
    "        Used to embed the `tokens` `TextField` we get as input to the model.\n",
    "    turn_encoder : `Seq2VeqEncoder`\n",
    "        The encoder that we will use to generate representation for whole turns from tokens.\n",
    "    chat_encoder: `Seq2SeqEncoder`   The encoder that we will use to generate representations\n",
    "        of turns within a chat\n",
    "    arc_representation_dim : `int`, required.\n",
    "        The dimension of the MLPs used for arc prediction.\n",
    "        \n",
    "    feature_size : `int`\n",
    "        The embedding size for all the embedded features, such as distances\n",
    "        \n",
    "    tag_feedforward : `FeedForward`, optional, (default = None).\n",
    "        The feedforward network used to produce tag representations.\n",
    "        By default, a 1 layer feedforward network with an elu activation is used.\n",
    "    arc_feedforward : `FeedForward`, optional, (default = None).\n",
    "        The feedforward network used to produce arc representations.\n",
    "        By default, a 1 layer feedforward network with an elu activation is used.\n",
    "\n",
    "    dropout : `float`, optional, (default = 0.0)\n",
    "        The variational dropout applied to the output of the encoder and MLP layers.\n",
    "    input_dropout : `float`, optional, (default = 0.0)\n",
    "        The dropout applied to the embedded text input.\n",
    "    edge_prediction_threshold : `int`, optional (default = 0.5)\n",
    "        The probability at which to consider a scored edge to be 'present'\n",
    "        in the decoded graph. Must be between 0 and 1.\n",
    "    initializer : `InitializerApplicator`, optional (default=`InitializerApplicator()`)\n",
    "        Used to initialize the model parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab: Vocabulary,\n",
    "        text_field_embedder: TextFieldEmbedder,\n",
    "        turn_encoder: Seq2VecEncoder, \n",
    "        chat_encoder: Seq2SeqEncoder,\n",
    "        arc_representation_dim: int,\n",
    "        feature_size = 4,\n",
    "        arc_feedforward: FeedForward = None,\n",
    "        use_features = False,\n",
    "        turn_feature_size = 0,# total dimension of turn-based additional features\n",
    "        pair_feature_size = 0,# total dimension of pair-based additional features\n",
    "        dropout: float = 0.3,\n",
    "        input_dropout: float = 0.0,\n",
    "        edge_prediction_threshold: float = 0.5,\n",
    "        positive_class_weight = 40,\n",
    "        prediction_window = 13, # dont predict edge further apart\n",
    "        initializer: InitializerApplicator = InitializerApplicator(),\n",
    "        debug = False,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        super().__init__(vocab, **kwargs)\n",
    "        \n",
    "        self.text_field_embedder = text_field_embedder\n",
    "        self.turn_encoder = TimeDistributed(turn_encoder)\n",
    "        self.chat_encoder = chat_encoder\n",
    "        \n",
    "        self.edge_prediction_threshold = edge_prediction_threshold\n",
    "        if not 0 < edge_prediction_threshold < 1:\n",
    "            raise ConfigurationError(\n",
    "                f\"edge_prediction_threshold must be between \"\n",
    "                f\"0 and 1 (exclusive) but found {edge_prediction_threshold}.\"\n",
    "            )\n",
    "\n",
    "        encoder_dim = chat_encoder.get_output_dim()\n",
    "        \n",
    "        self.use_features = use_features\n",
    "        self.turn_feature_size = turn_feature_size\n",
    "        self.pair_feature_size = pair_feature_size\n",
    "        \n",
    "        self.head_arc_feedforward = FeedForward(\n",
    "            encoder_dim+self.turn_feature_size, 1, arc_representation_dim, Activation.by_name(\"relu\")()\n",
    "        )\n",
    "        self.child_arc_feedforward = copy.deepcopy(self.head_arc_feedforward)\n",
    "\n",
    "        # 10 possible distance buckets.\n",
    "        if self.use_features:\n",
    "            self._num_distance_buckets = 10\n",
    "            self._distance_embedding = Embedding(\n",
    "                embedding_dim=feature_size, num_embeddings=self._num_distance_buckets\n",
    "            )\n",
    "            total_feature_size = self.pair_feature_size\n",
    "        \n",
    "        #\n",
    "        #self.arc_attention = BilinearMatrixAttention(\n",
    "        #    arc_representation_dim, arc_representation_dim, use_input_biases=True\n",
    "        #)\n",
    "        #self.arc_attention = DotProductMatrixAttention()\n",
    "        self.arc_attention = LinearMatrixAttention(\n",
    "            arc_representation_dim, arc_representation_dim, combination=\"x,y,x*y,x-y\", activation = None\n",
    "        )\n",
    "           \n",
    "        self.classif_layer = torch.nn.Linear(in_features=self.chat_encoder.hidden_size, out_features=2)\n",
    "        self._loss = torch.nn.CrossEntropyLoss()\n",
    "        self._dropout = InputVariationalDropout(dropout)\n",
    "        self._input_dropout = Dropout(input_dropout)\n",
    "        self.accuracy = CategoricalAccuracy()\n",
    "        self.f1measure = F1Measure(positive_label=1)\n",
    "        # unused for now\n",
    "        self.final_activation = Activation.by_name(\"sigmoid\")\n",
    "        # tested with distance feature (embedding) and spk_add boolean; final feedforward accounts also for attention scores\n",
    "        if self.use_features:\n",
    "            self.final_score = TimeDistributed(Linear(1+total_feature_size,1))#,self.final_activation))\n",
    "        \n",
    "        representation_dim = turn_encoder.get_output_dim()\n",
    "\n",
    "        self._unlabelled_f1 = F1Measure(positive_label=1)\n",
    "        #  with weight favoring recall of positive class \n",
    "        self._arc_loss = torch.nn.BCEWithLogitsLoss(reduction=\"none\",\n",
    "                                                    pos_weight=torch.tensor([positive_class_weight]))\n",
    "        \n",
    "        self.prediction_window = prediction_window\n",
    "        initializer(self)\n",
    "        # useful for debugging\n",
    "        self.iter_count = 0 \n",
    "        self.debug = debug\n",
    "    # init done\n",
    "        \n",
    "    # todo \n",
    "    @overrides\n",
    "    def forward(\n",
    "        self,  # type: ignore\n",
    "        lines,\n",
    "        arcs: torch.LongTensor = None,\n",
    "        loops = None,\n",
    "        rel_features = None,\n",
    "        offsets = None,\n",
    "        is_server = None,\n",
    "        metadata: List[Dict[str, Any]] = None,\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "\n",
    "        \"\"\"\n",
    "        # Parameters\n",
    "\n",
    "        lines: the chat as a list of turns, each being a list of token\n",
    "        TODO: add metadata to instances\n",
    "        metadata : List[Dict[str, Any]], optional (default = None)\n",
    "            A dictionary of metadata for each batch element which has keys:\n",
    "                tokens : `List[str]`, required.\n",
    "                    The original string tokens in the sentence.\n",
    "        arcs : a tensor containing the adjacency matrix for the instance dependencies between turns\n",
    "            Has shape `(batch_size, sequence_length, sequence_length)`.\n",
    "\n",
    "        # Returns\n",
    "\n",
    "        An output dictionary.\n",
    "        \"\"\"\n",
    "        #########\n",
    "        # this is the part where chat is encoded as sequence of turn encodings\n",
    "        #########\n",
    "        # mask for each turn of each chat of the batch: shape = (batch_size x max_turns x tokens)\n",
    "        token_mask = get_text_field_mask(lines,num_wrapping_dims=1)\n",
    "\n",
    "        # chat turns fetching embedding\n",
    "        # turns_embedding tensor is (batch_size x turns x max tokens x token embedding size)\n",
    "        turns_embeddings = self.text_field_embedder(lines,num_wrapping_dims=1)\n",
    "      \n",
    "        # encoding turns\n",
    "        # turn_h has shape (batch_size x turns x encoder_output_size) \n",
    "        turn_h = self.turn_encoder(turns_embeddings,token_mask)\n",
    "        \n",
    "        # mask for chats is now nb of turns; beware weird return type of torch.max (tuple) \n",
    "        chat_mask = token_mask.max(axis=2)[0]\n",
    "        \n",
    "        # renaming to mask -> easier to transpose the rest of graph_parser\n",
    "        mask = chat_mask\n",
    "        \n",
    "        # graph parser goes on\n",
    "        # leave input dropout for now\n",
    "        # embedded_text_input = turn_h equivalent in hierarchical sequence -> renaming \n",
    "        #embedded_text_input = self._input_dropout(embedded_text_input)\n",
    "        embedded_text_input = turn_h\n",
    "        \n",
    "        # encoded_turns = encoded chat = self.chat_encoder(turn_h,chat_mask) equivalent in hierarchical sequence\n",
    "        encoded_turns = self.chat_encoder(embedded_text_input, mask)\n",
    "        #breakpoint()\n",
    "        encoded_turns = self._dropout(encoded_turns)\n",
    "        \n",
    "        \n",
    "        \n",
    "        logits = self.classif_layer(encoded_turns)[:,-1,:]\n",
    "        probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        output_dict = {\"logits\": logits, \"probs\": probs, \"label\": loops}\n",
    "        #print(logits, probs, loops)\n",
    "        #for k, label in enumerate(loops):\n",
    "            #if \"server\" not in [x[\"tokens\"][-1] for x in metadata][k][1]:\n",
    "                #print(label, probs[k], [x[\"tokens\"][-1] for x in metadata][k])\n",
    "\n",
    "        if loops is not None:\n",
    "#            print(logits, loops)\n",
    "#            print(loops.long().view(-1))\n",
    "#            print(logits.size(), loops.size())\n",
    "            loss = self._loss(logits, loops.long().view(-1))\n",
    "            output_dict[\"loss\"] = loss\n",
    "            self.f1measure(logits, loops)\n",
    "            self.accuracy(logits, loops)\n",
    "        \n",
    "        return output_dict\n",
    "    # modified / partially tested\n",
    "    def _construct_loss(\n",
    "        self,\n",
    "        arc_scores: torch.Tensor,\n",
    "        arc_tags: torch.Tensor,\n",
    "        mask: torch.BoolTensor,\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Computes the arc loss for an adjacency matrix.\n",
    "\n",
    "        # Parameters\n",
    "\n",
    "        arc_scores : `torch.Tensor`, required.\n",
    "            A tensor of shape (batch_size, sequence_length, sequence_length) used to generate a\n",
    "            binary classification decision for whether an edge is present between two words.\n",
    "        arc_tags : `torch.Tensor`, required.\n",
    "            A tensor of shape (batch_size, sequence_length, sequence_length).\n",
    "            The labels for every arc (0/1).\n",
    "        mask : `torch.BoolTensor`, required.\n",
    "            A mask of shape (batch_size, sequence_length), denoting unpadded\n",
    "            elements in the sequence.\n",
    "\n",
    "        # Returns\n",
    "\n",
    "        arc_nll : `torch.Tensor`, required.\n",
    "            The negative log likelihood from the arc loss.\n",
    "        tag_nll : `torch.Tensor`, required.\n",
    "            The negative log likelihood from the arc tag loss.\n",
    "        \"\"\"\n",
    "        arc_indices = (arc_tags != -1).float()\n",
    "        # Make the arc tags not have negative values anywhere\n",
    "        # (by default, no edge is indicated with -1).\n",
    "        arc_tags = arc_tags * arc_indices\n",
    "        arc_nll = self._arc_loss(arc_scores, arc_indices) * mask.unsqueeze(1) * mask.unsqueeze(2)\n",
    "        \n",
    "        # We want the mask for the tags to only include the unmasked words\n",
    "        # and we only care about the loss with respect to the gold arcs.\n",
    "        tag_mask = mask.unsqueeze(1) * mask.unsqueeze(2) * arc_indices\n",
    "\n",
    "        #batch_size, sequence_length, _, num_tags = arc_tag_logits.size()\n",
    "        #original_shape = [batch_size, sequence_length, sequence_length]\n",
    "        #reshaped_logits = arc_tag_logits.view(-1, num_tags)\n",
    "        reshaped_tags = arc_tags.view(-1)\n",
    "        #tag_nll = (\n",
    "        #    self._tag_loss(reshaped_logits, reshaped_tags.long()).view(original_shape) * tag_mask\n",
    "        #)\n",
    "\n",
    "        valid_positions = tag_mask.sum()\n",
    "\n",
    "        arc_nll = arc_nll.sum() / valid_positions.float()\n",
    "        #tag_nll = tag_nll.sum() / valid_positions.float()\n",
    "        return arc_nll#, tag_nll\n",
    "    \n",
    "    \n",
    "    # modified / untested\n",
    "    # Warning: the initial Dozat & Manning implementation filter prediction with threshold here instead\n",
    "    # of decoding, but not in latest 1.1 allennlp version\n",
    "    #-------\n",
    "    # this is supposed to be called when ? doc unclear. says with model.forward_on_instances but does not seem\n",
    "    # to be the case (see tests below)\n",
    "    #-------\n",
    "    # no method for Model in used version (0.9?)\n",
    "    #@overrides\n",
    "    def make_output_human_readable(\n",
    "        self, output_dict: Dict[str, torch.Tensor]\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        #breakpoint()\n",
    "        arc_probs = output_dict[\"arc_probs\"].cpu().detach().numpy()\n",
    "        mask = output_dict[\"mask\"]\n",
    "        lengths = get_lengths_from_binary_sequence_mask(mask)\n",
    "        arcs = []\n",
    "        arc_tags = []\n",
    "        for instance_arc_probs, length in zip(\n",
    "            arc_probs, lengths\n",
    "        ):\n",
    "\n",
    "            arc_matrix = instance_arc_probs > self.edge_prediction_threshold\n",
    "            edges = []\n",
    "            #edge_tags = []\n",
    "            for i in range(length):\n",
    "                for j in range(length):\n",
    "                    if arc_matrix[i, j] == 1:\n",
    "                        edges.append((i, j))\n",
    "                        #tag = instance_arc_tag_probs[i, j].argmax(-1)\n",
    "                        #edge_tags.append(self.vocab.get_token_from_index(tag, \"labels\"))\n",
    "            arcs.append(edges)\n",
    "            #arc_tags.append(edge_tags)\n",
    "\n",
    "        output_dict[\"arcs\"] = arcs\n",
    "        #output_dict[\"arc_tags\"] = arc_tags\n",
    "        return output_dict\n",
    "    \n",
    "    \n",
    "    \n",
    "    # modified/partially tested\n",
    "    @staticmethod\n",
    "    def _greedy_decode(\n",
    "        arc_scores: torch.Tensor, \n",
    "        mask: torch.BoolTensor,\n",
    "        prediction_window: int,\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Decodes the head and head tag predictions by decoding the unlabeled arcs\n",
    "        independently for each word and then again, predicting the head tags of\n",
    "        these greedily chosen arcs independently.\n",
    "\n",
    "        # Parameters\n",
    "\n",
    "        arc_scores : `torch.Tensor`, required.\n",
    "            A tensor of shape (batch_size, sequence_length, sequence_length) used to generate\n",
    "            a distribution over attachments of a given word to all other words.\n",
    "        ###arc_tag_logits : `torch.Tensor`, required.\n",
    "        ###    A tensor of shape (batch_size, sequence_length, sequence_length, num_tags) used to\n",
    "        ###    generate a distribution over tags for each arc.\n",
    "        mask : `torch.BoolTensor`, required.\n",
    "            A mask of shape (batch_size, sequence_length).\n",
    "\n",
    "        # Returns\n",
    "\n",
    "        arc_probs : `torch.Tensor`\n",
    "            A tensor of shape (batch_size, sequence_length, sequence_length) representing the\n",
    "            probability of an arc being present for this edge.\n",
    "        ####arc_tag_probs : `torch.Tensor`\n",
    "        ####    A tensor of shape (batch_size, sequence_length, sequence_length, sequence_length)\n",
    "        ####    representing the distribution over edge tags for a given edge.\n",
    "        \"\"\"\n",
    "        # Mask the diagonal, because we don't self edges.\n",
    "        # WARNING: might not be the case for chats ? -> should be an option\n",
    "        #inf_diagonal_mask = torch.diag(arc_scores.new(mask.size(1)).fill_(-float('inf')))\n",
    "        \n",
    "        # no edges going backwards\n",
    "        triangle_upper_mask = torch.triu(arc_scores.new(mask.size(1),mask.size(1)).fill_(-float('inf')))\n",
    "        # prevent edges between turns more than prediction_window turns appart\n",
    "        up = 1-torch.triu(arc_scores.new(mask.size(1),mask.size(1)).fill_(1),diagonal=prediction_window)\n",
    "        down = 1-torch.tril(arc_scores.new(mask.size(1),mask.size(1)).fill_(1),diagonal=-prediction_window)\n",
    "        diag_mask = torch.log(((up+down)-1))\n",
    "        # up_mask = torch.triu(arc_scores.new_zeros(mask.size(1),mask.size(1),diagonal=-15)\n",
    "        # down_mask = torch.tril(arc_scores.new_zeros(mask.size(1),mask.size(1),diagonal=15)\n",
    "        # away_mask = (up_mask == down_mask)\n",
    "        #arc_scores = arc_scores + inf_diagonal_mask \n",
    "        arc_scores = arc_scores + diag_mask + triangle_upper_mask\n",
    "        \n",
    "        # shape (batch_size, sequence_length, sequence_length, num_tags)\n",
    "        #arc_tag_logits = arc_tag_logits + inf_diagonal_mask.unsqueeze(0).unsqueeze(-1)\n",
    "        # Mask padded tokens, because we only want to consider actual word -> word edges.\n",
    "        # CHAT: this is the wrong torch version lol this does not work/ confusion int/bools\n",
    "        # minus_mask = ~mask.unsqueeze(2)\n",
    "        # CHAT: this should work with torch>1.4\n",
    "        #minus_mask = (mask<1).unsqueeze(2)\n",
    "        minus_mask = (mask.unsqueeze(1) & mask.unsqueeze(2))<1\n",
    "        \n",
    "        arc_scores.masked_fill_(minus_mask, -float('inf'))\n",
    "        # \n",
    "        \n",
    "        #arc_tag_logits.masked_fill_(minus_mask.unsqueeze(-1), -float('inf'))\n",
    "        # shape (batch_size, sequence_length, sequence_length)\n",
    "        arc_probs = arc_scores.sigmoid()\n",
    "        # best arc option: set all but the best arc for a given target to 0 (== best head) \n",
    "        #force_max(arc_probs)\n",
    "        \n",
    "        # shape (batch_size, sequence_length, sequence_length, num_tags)\n",
    "        #arc_tag_probs = torch.nn.functional.softmax(arc_tag_logits, dim=-1)\n",
    "        return arc_probs#, arc_tag_probs\n",
    "    # modified / untested\n",
    "    \n",
    "    @overrides\n",
    "#    def get_metrics(self, reset: bool = False) -> Dict[str, float]:\n",
    "#        return {\"accuracy\": self.accuracy.get_metric(reset)}\n",
    "    def get_metrics(self, reset: bool = False) -> Dict[str, float]:\n",
    "        metrics = {}\n",
    "        metrics[\"accuracy\"] =  self.accuracy.get_metric(reset)\n",
    "        precision, recall, f1_measure = self.f1measure.get_metric(reset)\n",
    "        metrics[\"precision\"] = precision\n",
    "        metrics[\"recall\"] = recall\n",
    "        metrics[\"f1\"] = f1_measure\n",
    "        return metrics\n",
    "\n",
    "    # since human readable not accessible, post process the outputs of\n",
    "    # model.forward_on_instances\n",
    "    # includes prob threshold here\n",
    "    def extract_threshold(self,output_dict):\n",
    "        instance_arc_probs = output_dict[\"arc_probs\"]\n",
    "        mask = output_dict[\"mask\"]\n",
    "        length = len(mask)\n",
    "        if True:\n",
    "            arc_matrix = instance_arc_probs > self.edge_prediction_threshold\n",
    "            edges = []\n",
    "            for i in range(length):\n",
    "                for j in range(length):\n",
    "                    if arc_matrix[i, j] == 1:\n",
    "                        edges.append((i, j))\n",
    "\n",
    "        output_dict[\"arcs\"] = edges\n",
    "        return output_dict\n",
    "\n",
    "    def extract_best(self,output_dict):\n",
    "        best_heads = output_dict[\"arc_probs\"].argmax(axis=1)\n",
    "        best_values = output_dict[\"arc_probs\"].max(axis=1)\n",
    "        heads = list(zip(range(len(best_heads)),zip(best_heads,best_values)))\n",
    "        output_dict[\"arcs\"] = heads\n",
    "        return output_dict\n",
    "    \n",
    "    def predict_graph(self,instances,data_frame=False,best=False):\n",
    "        \"\"\"apply model on a bunch of instances\n",
    "\n",
    "        data_frame: if True, produce a pandas DataFrame, otherwise just add explicit edges to model output\n",
    "\n",
    "        best: if True, take only best head for each turn \n",
    "        \"\"\"\n",
    "        outputs = self.forward_on_instances(instances)\n",
    "        \n",
    "        if best:    \n",
    "            outputs = [model.extract_best(x) for x in outputs]\n",
    "        else:\n",
    "            outputs = [model.extract_threshold(x) for x in outputs]\n",
    "            \n",
    "        if not data_frame: \n",
    "            return outputs\n",
    "\n",
    "        # save only positive cases for now\n",
    "        frame = []\n",
    "        for one in outputs:\n",
    "            source = one[\"metadata\"][\"file_source\"]\n",
    "            start_idx = one[\"metadata\"][\"first_line\"]\n",
    "            #print(source,start_idx)\n",
    "            for (i,j) in one[\"arcs\"]:\n",
    "                if best: \n",
    "                    tid, label = j\n",
    "                else:\n",
    "                    tid, label = j,1\n",
    "                frame.append((source,i+start_idx,tid+start_idx,\"<sentence>\",\"<sentence>\",label))\n",
    "        return pds.DataFrame(frame,columns=[\"source_file\",\"source\",\"target\",\"sentence1\",\"sentence2\",\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_representation_dim = 50 \n",
    "feature_size = 4\n",
    "\n",
    "model = ChatGraphParser(vocab,word_embeddings,\n",
    "                        turn_encoder,chat_encoder,arc_representation_dim,\n",
    "                        use_features = True,\n",
    "                        turn_feature_size = 1,\n",
    "                        feature_size = feature_size,\n",
    "                        pair_feature_size = 1+feature_size,\n",
    "                        prediction_window = 10,\n",
    "                        positive_class_weight = 1000,\n",
    "                        debug=False,\n",
    "                        edge_prediction_threshold=0.55)\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    cuda_device = 0\n",
    "    model = model.cuda(cuda_device)\n",
    "else:\n",
    "    cuda_device = -1\n",
    "\n",
    "#cuda_device = -1\n",
    "    \n",
    "    \n",
    "# not used yet, but ready\n",
    "from allennlp.training.optimizers import Optimizer\n",
    "trainer_cfg = Params({\n",
    "        \"cuda_device\": cuda_device,\n",
    "        \"grad_norm\": 5,\n",
    "        \"num_epochs\": 100,\n",
    "        \"optimizer\": {\n",
    "            \"type\": \"dense_sparse_adam\",\n",
    "            \"betas\": [\n",
    "                0.9,\n",
    "                0.9\n",
    "            ]\n",
    "        },\n",
    "        \"patience\": 50,\n",
    "})\n",
    "opt_cfg = trainer_cfg.pop(\"optimizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "#optimizer = optim.SparseAdam(model.parameters(), lr=0.001)\n",
    "\n",
    "# not tested\n",
    "#optimizer = Optimizer.from_params(model_parameters=model.parameters(),\n",
    "#                                  params=opt_cfg)\n",
    "\n",
    "# \"lines\" <-> \"tokens\"\n",
    "iterator = BucketIterator(batch_size=512,\n",
    "                          sorting_keys=[(\"lines\",\"list_num_tokens\")])\n",
    "iterator.index_with(vocab)\n",
    "\n",
    "\n",
    "# requires Allennlp > 1.0\n",
    "#from allennlp.training.trainer import EpochCallback\n",
    "#class Epoch_nb(EpochCallback):\n",
    "#    \n",
    "#    def __call__(\n",
    "#          self,\n",
    "#          trainer: \"GradientDescentTrainer\",\n",
    "#          metrics: Dict[str, Any],\n",
    "#          epoch: int\n",
    "#      ) -> None:\n",
    "#        print(\"Epoch nb %d\"%epoch,end=\"\\t\")\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model,\n",
    "                  optimizer=optimizer,\n",
    "                  iterator=iterator,\n",
    "                  num_epochs=10,\n",
    "                  grad_norm=5,\n",
    "                  patience=10,\n",
    "                  cuda_device = cuda_device,\n",
    "                  train_dataset=train_instances,\n",
    "                  validation_dataset=dev_instances,\n",
    "                  serialization_dir=\"/data/sebastien/loops/training/train_\"+str(datetime.now().isoformat()), \n",
    "                  should_log_parameter_statistics = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (from tutorial) Here's how to save the model.\n",
    "with open(\"/data/sebastien/loops/model.th\", 'wb') as f:\n",
    "    torch.save(model.state_dict(), f)\n",
    "vocab.save_to_files(\"/data/sebastien/loops/vocabulary\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = ChatGraphParser(vocab,word_embeddings,\n",
    "                        turn_encoder,chat_encoder,arc_representation_dim,\n",
    "                        use_features = True,\n",
    "                        turn_feature_size = 1,\n",
    "                        feature_size = feature_size,\n",
    "                        pair_feature_size = 1+feature_size,\n",
    "                        prediction_window = 10,\n",
    "                        positive_class_weight = 1000,\n",
    "                        debug=False,\n",
    "                        edge_prediction_threshold=0.55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/data/sebastien/loops/training/train_2021-01-19T16:29:46.403784/model_state_epoch_5.th\", 'rb') as f:\n",
    "    model2.load_state_dict(torch.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGraphParser(\n",
       "  (text_field_embedder): BasicTextFieldEmbedder(\n",
       "    (token_embedder_tokens): Embedding()\n",
       "  )\n",
       "  (turn_encoder): TimeDistributed(\n",
       "    (_module): PytorchSeq2VecWrapper(\n",
       "      (_module): GRU(300, 100, batch_first=True, dropout=0.25, bidirectional=True)\n",
       "    )\n",
       "  )\n",
       "  (chat_encoder): PytorchSeq2SeqWrapper(\n",
       "    (_module): GRU(200, 100, num_layers=3, batch_first=True, dropout=0.25)\n",
       "  )\n",
       "  (head_arc_feedforward): FeedForward(\n",
       "    (_linear_layers): ModuleList(\n",
       "      (0): Linear(in_features=101, out_features=50, bias=True)\n",
       "    )\n",
       "    (_dropout): ModuleList(\n",
       "      (0): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (child_arc_feedforward): FeedForward(\n",
       "    (_linear_layers): ModuleList(\n",
       "      (0): Linear(in_features=101, out_features=50, bias=True)\n",
       "    )\n",
       "    (_dropout): ModuleList(\n",
       "      (0): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (_distance_embedding): Embedding()\n",
       "  (arc_attention): LinearMatrixAttention()\n",
       "  (classif_layer): Linear(in_features=100, out_features=2, bias=True)\n",
       "  (_loss): CrossEntropyLoss()\n",
       "  (_dropout): InputVariationalDropout(p=0.3, inplace=False)\n",
       "  (_input_dropout): Dropout(p=0.0, inplace=False)\n",
       "  (final_score): TimeDistributed(\n",
       "    (_module): Linear(in_features=6, out_features=1, bias=True)\n",
       "  )\n",
       "  (_arc_loss): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_instances = reader.read(\"../data/dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model2.forward_on_instances(dev_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"loops_prediction.tsv\", \"w\") as f:\n",
    "    f.write(\"index\\tfile_id\\tsource\\ttarget\\tsentence\\tlabel\\tproba0\\tproba1\\tprediction\\n\")\n",
    "    for i in range(len(dev_instances)):\n",
    "        f.write(f\"{i}\\t{dev_instances[i]['metadata'].metadata['file_source']}\"\n",
    "              + f\"\\t{dev_instances[i]['metadata'].metadata['token_line']}\"\n",
    "              + f\"\\t{dev_instances[i]['metadata'].metadata['token_line']}\"\n",
    "              + \"\\t\"+\" \".join(map(str, dev_instances[i]['metadata'].metadata['tokens'][-1]))\n",
    "              + f\"\\t{dev_instances[i]['loops'].label}\"\n",
    "              + f\"\\t{outputs[i]['probs'][0]}\"\n",
    "              + f\"\\t{outputs[i]['probs'][1]}\"\n",
    "              + f\"\\t{outputs[i]['probs'].argmax()}\\n\"\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4999it [00:02, 2032.48it/s]\n"
     ]
    }
   ],
   "source": [
    "test_instances = reader.read(\"../data/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encountered the loss key in the model's return dictionary which couldn't be split by the batch size. Key will be ignored.\n"
     ]
    }
   ],
   "source": [
    "outputs = model2.forward_on_instances(test_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_loops_prediction.tsv\", \"w\") as f:\n",
    "    f.write(\"index\\tfile_id\\tsource\\ttarget\\tsentence\\tlabel\\tproba0\\tproba1\\tprediction\\n\")\n",
    "    for i in range(len(test_instances)):\n",
    "        f.write(f\"{i}\\t{test_instances[i]['metadata'].metadata['file_source']}\"\n",
    "              + f\"\\t{test_instances[i]['metadata'].metadata['token_line']}\"\n",
    "              + f\"\\t{test_instances[i]['metadata'].metadata['token_line']}\"\n",
    "              + \"\\t\"+\" \".join(map(str, test_instances[i]['metadata'].metadata['tokens'][-1]))\n",
    "              + f\"\\t{test_instances[i]['loops'].label}\"\n",
    "              + f\"\\t{outputs[i]['probs'][0]}\"\n",
    "              + f\"\\t{outputs[i]['probs'][1]}\"\n",
    "              + f\"\\t{outputs[i]['probs'].argmax()}\\n\"\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1m = F1Measure(positive_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Could not infer dtype of LabelField",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-a586e7049af7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mf1m\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logits\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loops'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_instances\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not infer dtype of LabelField"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "f1m(torch.tensor([x[\"logits\"] for x in outputs]), torch.tensor([x['loops'] for x in test_instances]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.02097616, -0.05523992], dtype=float32),\n",
       " array([ 0.02097616, -0.05523992], dtype=float32),\n",
       " array([ 0.02097616, -0.05523992], dtype=float32),\n",
       " array([ 0.02097616, -0.05523992], dtype=float32),\n",
       " array([ 0.02097616, -0.05523992], dtype=float32),\n",
       " array([ 0.02097616, -0.05523992], dtype=float32),\n",
       " array([ 0.02097616, -0.05523992], dtype=float32),\n",
       " array([ 0.02097616, -0.05523992], dtype=float32),\n",
       " array([ 0.02097616, -0.05523992], dtype=float32),\n",
       " array([ 0.02097616, -0.05523992], dtype=float32),\n",
       " array([ 2.1005635, -1.7159123], dtype=float32),\n",
       " array([ 0.76982343, -0.48564577], dtype=float32),\n",
       " array([ 1.790357 , -1.2614411], dtype=float32),\n",
       " array([ 3.362391, -3.034902], dtype=float32),\n",
       " array([-0.9483521,  0.6841781], dtype=float32),\n",
       " array([ 2.7722416, -2.4350452], dtype=float32),\n",
       " array([ 1.4719468, -1.1286428], dtype=float32),\n",
       " array([ 2.6732879, -2.068485 ], dtype=float32),\n",
       " array([ 1.7999927, -1.5936846], dtype=float32),\n",
       " array([ 3.0509598, -2.523812 ], dtype=float32),\n",
       " array([ 2.6445298, -2.1513155], dtype=float32),\n",
       " array([-1.2669454,  1.2889928], dtype=float32),\n",
       " array([-1.1373951,  1.0267383], dtype=float32),\n",
       " array([-0.7734133 ,  0.71575123], dtype=float32),\n",
       " array([ 2.3056345, -2.069721 ], dtype=float32),\n",
       " array([ 2.8219366, -2.3430963], dtype=float32),\n",
       " array([ 2.3014984, -2.000256 ], dtype=float32),\n",
       " array([ 1.2236419, -1.5218387], dtype=float32),\n",
       " array([ 1.8460735, -1.5424109], dtype=float32),\n",
       " array([ 2.632629 , -2.0906146], dtype=float32),\n",
       " array([ 2.8268046, -2.2719834], dtype=float32),\n",
       " array([ 2.4422848, -2.0805194], dtype=float32),\n",
       " array([ 2.7029483, -2.7845697], dtype=float32),\n",
       " array([ 3.2296915, -3.062116 ], dtype=float32),\n",
       " array([ 2.571621 , -2.6789043], dtype=float32),\n",
       " array([ 2.7750034, -2.162999 ], dtype=float32),\n",
       " array([ 1.7602397, -1.5644431], dtype=float32),\n",
       " array([-0.7217635,  1.0296074], dtype=float32),\n",
       " array([ 2.9678683, -3.1620262], dtype=float32),\n",
       " array([ 2.9550195, -2.1428537], dtype=float32),\n",
       " array([ 3.0771742, -2.3517506], dtype=float32),\n",
       " array([ 2.0736217, -1.2937927], dtype=float32),\n",
       " array([ 2.2054749, -1.5562397], dtype=float32),\n",
       " array([ 3.28517  , -2.8429177], dtype=float32),\n",
       " array([ 2.8347235, -2.0951521], dtype=float32),\n",
       " array([-1.4859624,  1.3937843], dtype=float32),\n",
       " array([ 2.6231153, -2.3146956], dtype=float32),\n",
       " array([ 2.322108 , -2.2963402], dtype=float32),\n",
       " array([ 2.5464773, -2.0585554], dtype=float32),\n",
       " array([-0.95879185,  0.7728619 ], dtype=float32),\n",
       " array([ 1.2985011, -1.4144533], dtype=float32),\n",
       " array([ 3.0386953, -2.4128118], dtype=float32),\n",
       " array([ 2.449934 , -2.2927196], dtype=float32),\n",
       " array([ 3.33745  , -2.9776351], dtype=float32),\n",
       " array([ 2.7988245, -2.3447573], dtype=float32),\n",
       " array([ 2.4870386, -1.8940854], dtype=float32),\n",
       " array([ 2.5375009, -1.9287636], dtype=float32),\n",
       " array([ 2.9561257, -1.7242913], dtype=float32),\n",
       " array([ 3.0304809, -2.3760507], dtype=float32),\n",
       " array([ 1.2510632, -1.1224258], dtype=float32),\n",
       " array([ 2.6112494, -2.4613278], dtype=float32),\n",
       " array([ 3.0278945, -2.726682 ], dtype=float32),\n",
       " array([ 1.6275394, -1.007675 ], dtype=float32),\n",
       " array([ 2.3656707, -2.345478 ], dtype=float32),\n",
       " array([ 2.0916486, -1.6891153], dtype=float32),\n",
       " array([ 1.8743808, -1.5184834], dtype=float32),\n",
       " array([ 2.5831752, -1.931714 ], dtype=float32),\n",
       " array([ 3.028463 , -2.3714304], dtype=float32),\n",
       " array([ 2.3834012, -2.2445374], dtype=float32),\n",
       " array([-1.6327893,  1.7397933], dtype=float32),\n",
       " array([ 3.0721161, -2.5317419], dtype=float32),\n",
       " array([-1.7013575,  1.6269057], dtype=float32),\n",
       " array([ 2.1132953, -2.0266783], dtype=float32),\n",
       " array([ 1.9977819, -2.0161893], dtype=float32),\n",
       " array([ 2.9445   , -2.3288243], dtype=float32),\n",
       " array([ 2.90864  , -3.1647508], dtype=float32),\n",
       " array([ 3.2717423, -2.3538985], dtype=float32),\n",
       " array([ 2.9958923, -2.2425535], dtype=float32),\n",
       " array([ 2.8392055, -2.4743037], dtype=float32),\n",
       " array([ 3.1826653, -3.2600796], dtype=float32),\n",
       " array([-0.6938809,  0.6176425], dtype=float32),\n",
       " array([ 1.9960014, -1.551226 ], dtype=float32),\n",
       " array([ 2.849267, -2.049974], dtype=float32),\n",
       " array([ 3.10646  , -2.3692605], dtype=float32),\n",
       " array([ 2.2003202, -1.4793003], dtype=float32),\n",
       " array([ 1.6596521, -1.454836 ], dtype=float32),\n",
       " array([ 2.3494868, -2.2295995], dtype=float32),\n",
       " array([ 2.9155035, -2.1511006], dtype=float32),\n",
       " array([ 3.2485762, -2.8359253], dtype=float32),\n",
       " array([ 2.0361907, -1.6620581], dtype=float32),\n",
       " array([ 3.5223908, -3.021836 ], dtype=float32),\n",
       " array([ 1.4447923, -0.8889601], dtype=float32),\n",
       " array([ 2.7023344, -2.954344 ], dtype=float32),\n",
       " array([ 2.1706464, -1.9084424], dtype=float32),\n",
       " array([ 2.996743, -2.39174 ], dtype=float32),\n",
       " array([ 1.7991513, -1.3657138], dtype=float32),\n",
       " array([ 2.832929 , -2.0670593], dtype=float32),\n",
       " array([ 2.5430522, -2.4755025], dtype=float32),\n",
       " array([-1.138749 ,  1.2091923], dtype=float32),\n",
       " array([ 1.7969141, -1.5037196], dtype=float32),\n",
       " array([ 1.8547142, -1.7522571], dtype=float32),\n",
       " array([ 3.1750202, -2.58619  ], dtype=float32),\n",
       " array([ 2.7636614, -2.6147509], dtype=float32),\n",
       " array([ 3.755086 , -2.9284012], dtype=float32),\n",
       " array([ 2.626646 , -2.6715891], dtype=float32),\n",
       " array([ 2.5526605, -2.4916575], dtype=float32),\n",
       " array([ 3.435943 , -2.2507422], dtype=float32),\n",
       " array([ 2.8802655, -2.0976942], dtype=float32),\n",
       " array([ 3.1576242, -2.7549553], dtype=float32),\n",
       " array([ 0.81433964, -0.36326924], dtype=float32),\n",
       " array([ 1.5652912, -1.0119244], dtype=float32),\n",
       " array([ 2.6953797, -2.8051944], dtype=float32),\n",
       " array([ 3.8073146, -2.7295916], dtype=float32),\n",
       " array([ 1.8904372, -1.4623398], dtype=float32),\n",
       " array([ 2.0984771, -2.360241 ], dtype=float32),\n",
       " array([ 2.974424 , -2.7343357], dtype=float32),\n",
       " array([ 2.9655957, -2.7749236], dtype=float32),\n",
       " array([ 3.5697646, -2.854114 ], dtype=float32),\n",
       " array([ 2.924623, -2.394313], dtype=float32),\n",
       " array([ 2.9017096, -2.6681578], dtype=float32),\n",
       " array([ 2.917491 , -2.9631565], dtype=float32),\n",
       " array([ 1.6979363, -1.3814292], dtype=float32),\n",
       " array([-0.2747137,  0.4018186], dtype=float32),\n",
       " array([ 2.7014165, -2.1976755], dtype=float32),\n",
       " array([ 2.783119 , -2.8255177], dtype=float32),\n",
       " array([ 2.9000616, -2.537734 ], dtype=float32),\n",
       " array([ 3.429461 , -3.1862757], dtype=float32),\n",
       " array([ 3.413862 , -3.1377113], dtype=float32),\n",
       " array([ 2.8879292, -2.7015245], dtype=float32),\n",
       " array([ 3.2792697, -2.8548167], dtype=float32),\n",
       " array([-1.8026392,  1.5097169], dtype=float32),\n",
       " array([ 2.3436818, -2.1955817], dtype=float32),\n",
       " array([ 3.0602617, -2.756336 ], dtype=float32),\n",
       " array([ 1.0207412, -0.5250454], dtype=float32),\n",
       " array([ 2.808055 , -2.2834632], dtype=float32),\n",
       " array([ 2.56961  , -2.2616017], dtype=float32),\n",
       " array([ 2.8816562, -2.708789 ], dtype=float32),\n",
       " array([ 2.7144856, -2.0253863], dtype=float32),\n",
       " array([ 1.166827 , -1.2663076], dtype=float32),\n",
       " array([ 1.0847627 , -0.41119394], dtype=float32),\n",
       " array([ 2.9020076, -2.5985878], dtype=float32),\n",
       " array([ 2.5853052, -2.5611074], dtype=float32),\n",
       " array([ 2.8382573, -2.6338937], dtype=float32),\n",
       " array([ 2.5389144, -2.3357966], dtype=float32),\n",
       " array([-0.777598  ,  0.74299693], dtype=float32),\n",
       " array([-3.0033336,  2.0696456], dtype=float32),\n",
       " array([ 2.2300222, -2.2485163], dtype=float32),\n",
       " array([ 2.2229776, -1.6239427], dtype=float32),\n",
       " array([ 2.8781977, -2.1985424], dtype=float32),\n",
       " array([ 2.4610043, -2.326121 ], dtype=float32),\n",
       " array([-0.84339285,  0.9440583 ], dtype=float32),\n",
       " array([ 2.551896 , -2.7635255], dtype=float32),\n",
       " array([ 2.6928356, -2.2024155], dtype=float32),\n",
       " array([-1.9223573,  2.0327244], dtype=float32),\n",
       " array([-2.1054115,  1.6386735], dtype=float32),\n",
       " array([-2.3828163,  1.8531339], dtype=float32),\n",
       " array([-0.2753504 ,  0.27880463], dtype=float32),\n",
       " array([ 1.3605218, -1.5465668], dtype=float32),\n",
       " array([-0.19383037,  0.05137409], dtype=float32),\n",
       " array([ 2.2356594, -2.555132 ], dtype=float32),\n",
       " array([ 3.4020016, -2.8881683], dtype=float32),\n",
       " array([ 1.85122  , -1.4969003], dtype=float32),\n",
       " array([ 3.1311555, -2.840496 ], dtype=float32),\n",
       " array([-0.38617876,  0.49259102], dtype=float32),\n",
       " array([-0.7289192 ,  0.43051803], dtype=float32),\n",
       " array([ 0.94935286, -0.7830975 ], dtype=float32),\n",
       " array([ 2.7099576, -2.6756165], dtype=float32),\n",
       " array([ 3.0945563, -2.582277 ], dtype=float32),\n",
       " array([ 2.9335246, -2.2309165], dtype=float32),\n",
       " array([ 2.4670258, -1.5785975], dtype=float32),\n",
       " array([ 2.4364238, -2.1039565], dtype=float32),\n",
       " array([ 1.914887 , -1.2030181], dtype=float32),\n",
       " array([ 2.5426395, -1.4598594], dtype=float32),\n",
       " array([0.42492506, 0.25636962], dtype=float32),\n",
       " array([ 2.517254 , -2.6053722], dtype=float32),\n",
       " array([ 3.5354543, -3.118657 ], dtype=float32),\n",
       " array([ 2.4341888, -2.2722633], dtype=float32),\n",
       " array([ 3.0967135, -2.3072484], dtype=float32),\n",
       " array([ 4.2379556, -3.544564 ], dtype=float32),\n",
       " array([ 1.5531797, -1.1324213], dtype=float32),\n",
       " array([ 2.9860368, -2.6091552], dtype=float32),\n",
       " array([ 2.5367966, -2.3299842], dtype=float32),\n",
       " array([ 2.9850094, -2.1856716], dtype=float32),\n",
       " array([-0.7473875,  0.6445314], dtype=float32),\n",
       " array([ 1.5501037, -1.7968545], dtype=float32),\n",
       " array([ 1.8251156, -1.5168691], dtype=float32),\n",
       " array([ 3.2620606, -2.6612604], dtype=float32),\n",
       " array([ 3.5714712, -2.4010122], dtype=float32),\n",
       " array([ 2.8761027, -2.1516922], dtype=float32),\n",
       " array([ 1.8450646, -1.6568195], dtype=float32),\n",
       " array([ 2.9042962, -2.2453804], dtype=float32),\n",
       " array([ 2.2838094, -1.849643 ], dtype=float32),\n",
       " array([ 0.44385138, -0.23654039], dtype=float32),\n",
       " array([ 1.9250013, -1.6606448], dtype=float32),\n",
       " array([ 2.2330446, -1.5156631], dtype=float32),\n",
       " array([ 2.2318606, -1.8315501], dtype=float32),\n",
       " array([ 3.2593927, -2.751312 ], dtype=float32),\n",
       " array([ 3.160747 , -2.8196163], dtype=float32),\n",
       " array([-1.0897201,  1.091389 ], dtype=float32),\n",
       " array([ 2.6801372, -2.334836 ], dtype=float32),\n",
       " array([ 1.7637581 , -0.82399035], dtype=float32),\n",
       " array([ 2.723822 , -2.4915066], dtype=float32),\n",
       " array([-1.7515094,  1.7133746], dtype=float32),\n",
       " array([-1.3151261,  1.0570947], dtype=float32),\n",
       " array([ 1.5424079, -1.255113 ], dtype=float32),\n",
       " array([ 0.6385796, -0.7494422], dtype=float32),\n",
       " array([ 1.8091077, -1.7705783], dtype=float32),\n",
       " array([ 2.9093828, -2.7321136], dtype=float32),\n",
       " array([ 0.25731346, -0.14261186], dtype=float32),\n",
       " array([ 1.2062359, -1.0196975], dtype=float32),\n",
       " array([ 1.6225971, -1.2444578], dtype=float32),\n",
       " array([ 1.9676414, -2.1018155], dtype=float32),\n",
       " array([ 2.86563  , -2.4039214], dtype=float32),\n",
       " array([ 4.271906 , -2.9901679], dtype=float32),\n",
       " array([ 2.2731416, -1.5765433], dtype=float32),\n",
       " array([ 2.743143 , -2.2192538], dtype=float32),\n",
       " array([-1.6939242,  1.862993 ], dtype=float32),\n",
       " array([ 2.215322, -2.218538], dtype=float32),\n",
       " array([ 3.1178832, -2.1999009], dtype=float32),\n",
       " array([ 2.6475215, -1.7041819], dtype=float32),\n",
       " array([ 0.5126055 , -0.57406795], dtype=float32),\n",
       " array([ 2.8652263, -2.33279  ], dtype=float32),\n",
       " array([ 1.7109307, -1.7783644], dtype=float32),\n",
       " array([ 3.2904172, -2.9614298], dtype=float32),\n",
       " array([-1.680952 ,  1.6528041], dtype=float32),\n",
       " array([-0.5940341,  0.5357544], dtype=float32),\n",
       " array([ 0.8559418, -0.5131119], dtype=float32),\n",
       " array([ 2.603459 , -2.5186944], dtype=float32),\n",
       " array([ 1.0644621, -0.6375349], dtype=float32),\n",
       " array([ 2.9731889, -2.564501 ], dtype=float32),\n",
       " array([-1.888384 ,  1.7719482], dtype=float32),\n",
       " array([ 2.4685602, -2.890075 ], dtype=float32),\n",
       " array([ 2.027243 , -1.7034758], dtype=float32),\n",
       " array([ 2.706632 , -2.1648579], dtype=float32),\n",
       " array([ 2.6413503, -2.7718084], dtype=float32),\n",
       " array([ 2.2028904, -1.8964595], dtype=float32),\n",
       " array([-1.6886729,  1.4842288], dtype=float32),\n",
       " array([ 1.9665599, -1.3678998], dtype=float32),\n",
       " array([ 3.1894064, -2.9632192], dtype=float32),\n",
       " array([ 0.4185725 , -0.13724194], dtype=float32),\n",
       " array([ 2.6047754, -2.2543712], dtype=float32),\n",
       " array([ 2.9653416, -2.7535448], dtype=float32),\n",
       " array([ 1.1286048, -1.0849965], dtype=float32),\n",
       " array([ 2.5097694, -2.442396 ], dtype=float32),\n",
       " array([ 3.1267133, -2.6694672], dtype=float32),\n",
       " array([ 2.8453732, -1.9863145], dtype=float32),\n",
       " array([-1.4505256,  1.9051024], dtype=float32),\n",
       " array([ 2.4249978, -2.311978 ], dtype=float32),\n",
       " array([ 2.5010333, -2.4090095], dtype=float32),\n",
       " array([ 1.7402905, -1.438657 ], dtype=float32),\n",
       " array([ 2.4815047, -2.6469042], dtype=float32),\n",
       " array([-1.4150357,  1.4396133], dtype=float32),\n",
       " array([ 3.1320758, -2.3481948], dtype=float32),\n",
       " array([ 2.924736, -2.843703], dtype=float32),\n",
       " array([ 2.7546349, -2.2515743], dtype=float32),\n",
       " array([ 1.9095362, -1.5554845], dtype=float32),\n",
       " array([ 3.7173162, -3.1327755], dtype=float32),\n",
       " array([ 3.4025958, -2.9545984], dtype=float32),\n",
       " array([ 3.0702796, -2.9983737], dtype=float32),\n",
       " array([ 2.5142908, -2.5695257], dtype=float32),\n",
       " array([ 2.6466513, -2.6531522], dtype=float32),\n",
       " array([ 1.7890836, -1.7091014], dtype=float32),\n",
       " array([ 2.83333 , -2.615793], dtype=float32),\n",
       " array([ 2.6684306, -2.6934474], dtype=float32),\n",
       " array([ 2.7270632, -2.121036 ], dtype=float32),\n",
       " array([-0.3938339,  0.323185 ], dtype=float32),\n",
       " array([ 1.2862422, -0.7805505], dtype=float32),\n",
       " array([ 2.2851505, -2.1749227], dtype=float32),\n",
       " array([ 1.6756645, -1.1395402], dtype=float32),\n",
       " array([ 2.6708694, -2.615246 ], dtype=float32),\n",
       " array([ 3.2755294, -2.468806 ], dtype=float32),\n",
       " array([ 2.8549957, -2.5804145], dtype=float32),\n",
       " array([ 1.7050372, -1.3069175], dtype=float32),\n",
       " array([ 2.454555 , -1.8415794], dtype=float32),\n",
       " array([ 3.1717932, -2.1477015], dtype=float32),\n",
       " array([ 2.9878514, -2.4204462], dtype=float32),\n",
       " array([ 1.6793803, -0.888484 ], dtype=float32),\n",
       " array([ 3.4181142, -2.6476507], dtype=float32),\n",
       " array([ 2.7391133, -2.2027192], dtype=float32),\n",
       " array([-1.2247983,  1.2987857], dtype=float32),\n",
       " array([-1.9849437,  1.739001 ], dtype=float32),\n",
       " array([ 2.070045 , -2.2876465], dtype=float32),\n",
       " array([ 1.8745679, -1.5139732], dtype=float32),\n",
       " array([ 3.7788072, -3.1865585], dtype=float32),\n",
       " array([ 2.8005984, -2.5589955], dtype=float32),\n",
       " array([ 0.8745183 , -0.62152976], dtype=float32),\n",
       " array([ 2.0873454, -1.5095143], dtype=float32),\n",
       " array([ 3.1888418, -2.5109808], dtype=float32),\n",
       " array([ 1.8103873, -1.7338078], dtype=float32),\n",
       " array([ 2.7905207, -2.214495 ], dtype=float32),\n",
       " array([ 2.136138 , -1.6606007], dtype=float32),\n",
       " array([ 3.2766669, -2.7256992], dtype=float32),\n",
       " array([ 2.0098908, -1.1801767], dtype=float32),\n",
       " array([ 2.5696583, -2.3815973], dtype=float32),\n",
       " array([ 1.8014065, -1.8142521], dtype=float32),\n",
       " array([ 2.5025382, -2.6054022], dtype=float32),\n",
       " array([ 2.3909872, -1.7489251], dtype=float32),\n",
       " array([ 2.3515885, -1.5636978], dtype=float32),\n",
       " array([ 3.3471444, -2.9014053], dtype=float32),\n",
       " array([ 2.347037, -2.161484], dtype=float32),\n",
       " array([ 0.86111796, -0.91433436], dtype=float32),\n",
       " array([ 1.8976258, -1.8706188], dtype=float32),\n",
       " array([ 2.8267684, -2.5525854], dtype=float32),\n",
       " array([ 2.436313, -1.893519], dtype=float32),\n",
       " array([ 2.8111439, -2.53171  ], dtype=float32),\n",
       " array([ 2.6109233, -2.536403 ], dtype=float32),\n",
       " array([ 2.985225 , -3.0207317], dtype=float32),\n",
       " array([ 2.9214725, -2.519675 ], dtype=float32),\n",
       " array([ 2.9439018, -2.18533  ], dtype=float32),\n",
       " array([ 2.0875156, -2.0424821], dtype=float32),\n",
       " array([ 1.633149 , -1.2109662], dtype=float32),\n",
       " array([ 3.3676934, -3.213033 ], dtype=float32),\n",
       " array([ 2.9861689, -1.7727948], dtype=float32),\n",
       " array([ 2.7839828, -2.5573316], dtype=float32),\n",
       " array([ 2.8515162, -2.509987 ], dtype=float32),\n",
       " array([ 1.1346068 , -0.42233795], dtype=float32),\n",
       " array([ 3.0278769, -2.414728 ], dtype=float32),\n",
       " array([ 2.3206599, -1.93494  ], dtype=float32),\n",
       " array([ 2.760169 , -2.5086844], dtype=float32),\n",
       " array([ 2.2648594, -1.8416027], dtype=float32),\n",
       " array([ 3.3138423, -3.2281318], dtype=float32),\n",
       " array([-0.11869945,  0.3589064 ], dtype=float32),\n",
       " array([ 2.9784322, -2.7857206], dtype=float32),\n",
       " array([ 3.2894306, -3.2417016], dtype=float32),\n",
       " array([ 3.3848696, -2.8371608], dtype=float32),\n",
       " array([ 2.9137998, -2.5417244], dtype=float32),\n",
       " array([ 1.9847395, -1.609718 ], dtype=float32),\n",
       " array([ 2.194365 , -2.0455337], dtype=float32),\n",
       " array([ 2.758916 , -2.1618526], dtype=float32),\n",
       " array([ 2.4816425, -1.6199381], dtype=float32),\n",
       " array([ 2.2899365, -1.5930831], dtype=float32),\n",
       " array([ 3.0230722, -3.1906106], dtype=float32),\n",
       " array([ 3.2772613, -2.2661548], dtype=float32),\n",
       " array([ 3.1716216, -2.8004434], dtype=float32),\n",
       " array([ 3.6541648, -3.0395691], dtype=float32),\n",
       " array([ 3.9166684, -3.0876963], dtype=float32),\n",
       " array([ 2.4424915, -2.1826658], dtype=float32),\n",
       " array([ 3.0475788, -2.4930134], dtype=float32),\n",
       " array([ 2.9790366, -2.4466913], dtype=float32),\n",
       " array([ 3.6129937, -2.72031  ], dtype=float32),\n",
       " array([ 2.520253 , -2.4902103], dtype=float32),\n",
       " array([ 3.05959  , -3.3598502], dtype=float32),\n",
       " array([ 2.470645, -2.434106], dtype=float32),\n",
       " array([ 2.8871021, -2.706813 ], dtype=float32),\n",
       " array([ 2.457241 , -2.0492988], dtype=float32),\n",
       " array([ 3.023172 , -2.5407739], dtype=float32),\n",
       " array([ 2.891129 , -2.5346007], dtype=float32),\n",
       " array([ 2.6259787, -2.0935514], dtype=float32),\n",
       " array([ 3.1232274, -2.269227 ], dtype=float32),\n",
       " array([ 2.8714116, -3.1677902], dtype=float32),\n",
       " array([ 1.8396077, -1.7548902], dtype=float32),\n",
       " array([ 0.3423349 , -0.49437934], dtype=float32),\n",
       " array([ 1.8135204, -1.267011 ], dtype=float32),\n",
       " array([ 2.3257396, -2.303409 ], dtype=float32),\n",
       " array([ 2.8559089, -2.5691695], dtype=float32),\n",
       " array([ 1.57362  , -1.5087017], dtype=float32),\n",
       " array([ 2.0998623, -1.8845389], dtype=float32),\n",
       " array([ 1.4375654, -1.3961719], dtype=float32),\n",
       " array([ 1.7207859, -1.6707072], dtype=float32),\n",
       " array([ 2.420587 , -2.5712192], dtype=float32),\n",
       " array([ 2.6995125, -2.6186101], dtype=float32),\n",
       " array([ 2.5321455, -1.7686758], dtype=float32),\n",
       " array([ 1.8326614, -1.1830355], dtype=float32),\n",
       " array([ 1.8952326, -1.6725855], dtype=float32),\n",
       " array([-1.7893151,  1.4652574], dtype=float32),\n",
       " array([ 2.8556561, -2.2970839], dtype=float32),\n",
       " array([ 0.7992463, -0.5743566], dtype=float32),\n",
       " array([ 2.4704266, -2.3022032], dtype=float32),\n",
       " array([ 0.77373254, -0.5564588 ], dtype=float32),\n",
       " array([ 2.655262 , -2.5039382], dtype=float32),\n",
       " array([ 2.2266488, -1.6384275], dtype=float32),\n",
       " array([ 1.3831179 , -0.94395894], dtype=float32),\n",
       " array([ 1.6971322, -1.5513132], dtype=float32),\n",
       " array([ 2.6198215, -2.3889742], dtype=float32),\n",
       " array([ 3.416791 , -2.5518286], dtype=float32),\n",
       " array([ 2.6033993, -2.024019 ], dtype=float32),\n",
       " array([ 1.6683248, -1.0875938], dtype=float32),\n",
       " array([ 3.394794 , -2.5013242], dtype=float32),\n",
       " array([ 1.8411297, -1.1904378], dtype=float32),\n",
       " array([ 1.2226055, -1.3361273], dtype=float32),\n",
       " array([ 1.2594464, -0.7661875], dtype=float32),\n",
       " array([ 1.3905714, -0.9476797], dtype=float32),\n",
       " array([ 0.8213084, -0.6805595], dtype=float32),\n",
       " array([ 2.6107378, -2.6191518], dtype=float32),\n",
       " array([ 3.0263627, -2.6250033], dtype=float32),\n",
       " array([ 2.9463282, -3.1404517], dtype=float32),\n",
       " array([ 2.3666706, -2.0047555], dtype=float32),\n",
       " array([-0.25238192,  0.39160222], dtype=float32),\n",
       " array([ 3.1259358, -3.0337427], dtype=float32),\n",
       " array([ 1.148189 , -1.2534425], dtype=float32),\n",
       " array([ 2.765499 , -2.0797586], dtype=float32),\n",
       " array([ 3.592748 , -2.8448985], dtype=float32),\n",
       " array([ 2.940055, -2.586222], dtype=float32),\n",
       " array([-1.209057 ,  0.9438883], dtype=float32),\n",
       " array([ 2.7712502, -2.6223638], dtype=float32),\n",
       " array([ 2.2538478, -2.0315993], dtype=float32),\n",
       " array([ 2.348141 , -1.5094457], dtype=float32),\n",
       " array([ 3.3568802, -3.0690882], dtype=float32),\n",
       " array([ 2.5951707, -2.5824342], dtype=float32),\n",
       " array([ 2.7942648, -2.8601217], dtype=float32),\n",
       " array([ 2.6770902, -2.316178 ], dtype=float32),\n",
       " array([ 2.034681 , -1.2190387], dtype=float32),\n",
       " array([ 2.5040112, -2.2536561], dtype=float32),\n",
       " array([ 2.2328496, -1.8274128], dtype=float32),\n",
       " array([ 2.7355852, -2.5834415], dtype=float32),\n",
       " array([ 3.0858536, -2.3344038], dtype=float32),\n",
       " array([ 2.863002 , -2.4672115], dtype=float32),\n",
       " array([ 2.7151155, -2.1888404], dtype=float32),\n",
       " array([ 2.079117 , -1.3890034], dtype=float32),\n",
       " array([ 2.9017134, -2.260114 ], dtype=float32),\n",
       " array([ 3.4859517, -3.355903 ], dtype=float32),\n",
       " array([ 3.0730417, -2.615943 ], dtype=float32),\n",
       " array([ 2.3855615, -2.1940205], dtype=float32),\n",
       " array([ 3.1746922, -2.2390552], dtype=float32),\n",
       " array([ 1.9105034, -1.6468828], dtype=float32),\n",
       " array([ 2.7730732, -2.2624733], dtype=float32),\n",
       " array([ 1.445794, -1.18837 ], dtype=float32),\n",
       " array([ 2.5590873, -1.6601019], dtype=float32),\n",
       " array([-0.8902098,  0.5314178], dtype=float32),\n",
       " array([ 1.4573799, -1.1125952], dtype=float32),\n",
       " array([ 2.9462094, -2.729299 ], dtype=float32),\n",
       " array([ 0.5752825, -0.5804429], dtype=float32),\n",
       " array([ 1.3296764, -1.4169828], dtype=float32),\n",
       " array([-0.41525853,  0.33440292], dtype=float32),\n",
       " array([-0.03416016,  0.03281158], dtype=float32),\n",
       " array([ 1.883171 , -1.5952294], dtype=float32),\n",
       " array([ 2.7004373, -2.7730916], dtype=float32),\n",
       " array([ 3.0338578, -3.1106265], dtype=float32),\n",
       " array([ 2.1776183, -1.976522 ], dtype=float32),\n",
       " array([ 1.2766011, -0.9159483], dtype=float32),\n",
       " array([-0.7809576,  0.8393853], dtype=float32),\n",
       " array([ 1.1758333, -1.1287961], dtype=float32),\n",
       " array([ 1.7047349, -1.8432621], dtype=float32),\n",
       " array([ 1.6203065, -1.2774949], dtype=float32),\n",
       " array([ 1.6219602, -1.3420955], dtype=float32),\n",
       " array([-0.5593871,  0.859597 ], dtype=float32),\n",
       " array([ 0.5260374 , -0.46994907], dtype=float32),\n",
       " array([-2.3285692,  1.8485649], dtype=float32),\n",
       " array([ 0.9835638, -1.1272265], dtype=float32),\n",
       " array([ 1.3811334, -1.5195122], dtype=float32),\n",
       " array([ 0.20793998, -0.10108271], dtype=float32),\n",
       " array([ 2.7333584, -2.3288128], dtype=float32),\n",
       " array([ 1.630184, -1.166503], dtype=float32),\n",
       " array([ 2.3695927, -2.3031967], dtype=float32),\n",
       " array([ 2.7453945, -2.8678548], dtype=float32),\n",
       " array([ 2.1403728, -2.2628407], dtype=float32),\n",
       " array([ 2.3110485, -2.0051312], dtype=float32),\n",
       " array([ 2.614726 , -2.6865842], dtype=float32),\n",
       " array([-1.3927712,  1.0836706], dtype=float32),\n",
       " array([ 1.0605911, -1.0112631], dtype=float32),\n",
       " array([ 1.4519364, -1.2348223], dtype=float32),\n",
       " array([ 2.4571   , -2.6284997], dtype=float32),\n",
       " array([-0.07582775,  0.21893072], dtype=float32),\n",
       " array([ 2.7568598, -2.634342 ], dtype=float32),\n",
       " array([ 0.8676917, -0.3846088], dtype=float32),\n",
       " array([ 3.1335454, -2.8940322], dtype=float32),\n",
       " array([-0.84038043,  0.74770606], dtype=float32),\n",
       " array([-1.695788 ,  1.5482244], dtype=float32),\n",
       " array([ 1.9730533, -1.7889824], dtype=float32),\n",
       " array([ 2.0484536, -1.5422597], dtype=float32),\n",
       " array([ 2.3086915, -2.080938 ], dtype=float32),\n",
       " array([-1.2686672,  1.7168257], dtype=float32),\n",
       " array([ 2.3834677, -2.2068803], dtype=float32),\n",
       " array([ 2.9495559, -2.9589942], dtype=float32),\n",
       " array([ 2.9440603, -1.9930987], dtype=float32),\n",
       " array([ 1.9402825, -1.5282283], dtype=float32),\n",
       " array([ 1.1157374 , -0.93284774], dtype=float32),\n",
       " array([ 2.1422925, -1.9434423], dtype=float32),\n",
       " array([ 2.725608, -2.732332], dtype=float32),\n",
       " array([ 2.32852 , -2.303488], dtype=float32),\n",
       " array([ 1.9147373, -1.7363431], dtype=float32),\n",
       " array([ 2.7611322, -2.4617736], dtype=float32),\n",
       " array([ 1.8627144, -1.4950829], dtype=float32),\n",
       " array([ 2.2951756, -2.1385772], dtype=float32),\n",
       " array([ 3.3892853, -3.3867028], dtype=float32),\n",
       " array([ 2.6177523, -1.8606449], dtype=float32),\n",
       " array([ 3.0931973, -2.6964386], dtype=float32),\n",
       " array([ 1.4662248, -1.1000812], dtype=float32),\n",
       " array([ 0.67687815, -0.04621882], dtype=float32),\n",
       " array([ 1.4350866, -1.547148 ], dtype=float32),\n",
       " array([ 1.7882462, -1.4259454], dtype=float32),\n",
       " array([ 1.157503 , -1.1079496], dtype=float32),\n",
       " array([ 2.540205 , -1.7759832], dtype=float32),\n",
       " array([-1.3320867,  1.2607837], dtype=float32),\n",
       " array([-1.9123918,  1.7732815], dtype=float32),\n",
       " array([ 0.9090933, -1.1445588], dtype=float32),\n",
       " array([ 0.32045355, -0.25225967], dtype=float32),\n",
       " array([ 2.0729508, -1.9396362], dtype=float32),\n",
       " array([-1.7115873,  1.3200084], dtype=float32),\n",
       " array([ 1.4189842, -1.751282 ], dtype=float32),\n",
       " array([ 2.5141268, -2.1143591], dtype=float32),\n",
       " array([-1.940964 ,  1.8749475], dtype=float32),\n",
       " array([ 1.4817506, -1.6246176], dtype=float32),\n",
       " array([ 1.5826949, -1.0581756], dtype=float32),\n",
       " array([ 1.1582541, -1.6199006], dtype=float32),\n",
       " array([ 3.4045172, -2.9537132], dtype=float32),\n",
       " array([ 0.34446552, -0.2808074 ], dtype=float32),\n",
       " array([-0.19606252, -0.18479943], dtype=float32),\n",
       " array([ 2.0930586, -1.8313222], dtype=float32),\n",
       " array([ 2.219596 , -2.2358215], dtype=float32),\n",
       " array([ 0.02097616, -0.05523992], dtype=float32),\n",
       " array([ 0.02097616, -0.05523992], dtype=float32),\n",
       " array([ 0.02097616, -0.05523992], dtype=float32),\n",
       " array([ 0.02097616, -0.05523992], dtype=float32),\n",
       " array([ 0.02097616, -0.05523992], dtype=float32),\n",
       " array([ 0.02097616, -0.05523992], dtype=float32),\n",
       " array([ 0.02097616, -0.05523992], dtype=float32),\n",
       " array([ 0.02097616, -0.05523992], dtype=float32),\n",
       " array([ 0.02097616, -0.05523992], dtype=float32),\n",
       " array([ 0.02097616, -0.05523992], dtype=float32),\n",
       " array([ 2.40843 , -1.736014], dtype=float32),\n",
       " array([-0.7218462,  0.8634129], dtype=float32),\n",
       " array([-0.9370686 ,  0.83024514], dtype=float32),\n",
       " array([ 1.7505395, -2.2418005], dtype=float32),\n",
       " array([ 0.897617 , -0.6548206], dtype=float32),\n",
       " array([-2.2812243,  2.0505202], dtype=float32),\n",
       " array([-2.17116  ,  1.5190086], dtype=float32),\n",
       " array([ 1.2828761, -1.7399774], dtype=float32),\n",
       " array([-1.3650156 ,  0.87820756], dtype=float32),\n",
       " array([ 1.9521002, -1.8793633], dtype=float32),\n",
       " array([ 1.4583039, -1.4244571], dtype=float32),\n",
       " array([ 1.5491015, -1.2928573], dtype=float32),\n",
       " array([ 0.6447957, -0.6615673], dtype=float32),\n",
       " array([ 2.8475254, -2.532594 ], dtype=float32),\n",
       " array([ 0.97109663, -1.0008687 ], dtype=float32),\n",
       " array([ 1.5680773, -1.087454 ], dtype=float32),\n",
       " array([ 1.9151336, -1.5172756], dtype=float32),\n",
       " array([ 2.7858822, -2.1992962], dtype=float32),\n",
       " array([ 2.424078 , -2.6491222], dtype=float32),\n",
       " array([ 2.064701, -1.783353], dtype=float32),\n",
       " array([-0.7923427,  0.9043559], dtype=float32),\n",
       " array([-0.19326055,  0.2920237 ], dtype=float32),\n",
       " array([ 0.10544498, -0.02192024], dtype=float32),\n",
       " array([-0.08126577, -0.01479595], dtype=float32),\n",
       " array([ 2.4952457, -2.878435 ], dtype=float32),\n",
       " array([ 3.531772, -3.248589], dtype=float32),\n",
       " array([-0.44600046,  0.6311958 ], dtype=float32),\n",
       " array([ 1.7354488, -2.1485345], dtype=float32),\n",
       " array([ 2.315034 , -1.8212836], dtype=float32),\n",
       " array([ 2.598095, -2.534222], dtype=float32),\n",
       " array([ 3.235941 , -2.6666598], dtype=float32),\n",
       " array([ 2.754805 , -2.9123228], dtype=float32),\n",
       " array([ 3.3206043, -3.0306857], dtype=float32),\n",
       " array([ 2.1317666, -1.7590646], dtype=float32),\n",
       " array([ 3.1909726, -2.6560652], dtype=float32),\n",
       " array([ 3.3794494, -2.5744803], dtype=float32),\n",
       " array([ 1.1860822, -1.1090181], dtype=float32),\n",
       " array([-1.3640978,  1.1515163], dtype=float32),\n",
       " array([ 1.769214 , -1.8006986], dtype=float32),\n",
       " array([ 3.201569, -2.787245], dtype=float32),\n",
       " array([ 2.6206703, -2.4756224], dtype=float32),\n",
       " array([ 2.2818332, -2.0866725], dtype=float32),\n",
       " array([ 2.9494438, -2.309534 ], dtype=float32),\n",
       " array([ 1.7950512, -1.8470473], dtype=float32),\n",
       " array([ 2.3036158, -1.6656182], dtype=float32),\n",
       " array([ 2.7616923, -2.3307917], dtype=float32),\n",
       " array([-0.2240122 ,  0.43211383], dtype=float32),\n",
       " array([ 3.1134408, -2.6903555], dtype=float32),\n",
       " array([-2.048678 ,  1.7338848], dtype=float32),\n",
       " array([-1.3565468,  1.6384833], dtype=float32),\n",
       " array([-0.08201501, -0.0214012 ], dtype=float32),\n",
       " array([ 1.4989182, -1.5358379], dtype=float32),\n",
       " array([ 1.4268228, -1.2696644], dtype=float32),\n",
       " array([ 1.754526 , -1.5618961], dtype=float32),\n",
       " array([ 1.1339285, -1.0864896], dtype=float32),\n",
       " array([ 3.0829594, -2.3155603], dtype=float32),\n",
       " array([-0.8010087 ,  0.49890888], dtype=float32),\n",
       " array([-2.0884552,  1.7969366], dtype=float32),\n",
       " array([ 0.6633434 , -0.90491617], dtype=float32),\n",
       " array([-0.71273255,  0.21068776], dtype=float32),\n",
       " array([ 2.452233 , -2.2472756], dtype=float32),\n",
       " array([ 2.7966428, -2.901139 ], dtype=float32),\n",
       " array([ 3.1641557, -2.303098 ], dtype=float32),\n",
       " array([ 2.6186724, -2.6022341], dtype=float32),\n",
       " array([-0.8046963,  0.9031116], dtype=float32),\n",
       " array([ 2.0443058, -2.484655 ], dtype=float32),\n",
       " array([ 2.3457162, -1.9667382], dtype=float32),\n",
       " array([ 2.7872512, -2.7494586], dtype=float32),\n",
       " array([ 1.1443156 , -0.64347214], dtype=float32),\n",
       " array([ 2.0085645, -1.5916837], dtype=float32),\n",
       " array([ 2.5394368, -2.2941961], dtype=float32),\n",
       " array([ 1.3397635, -0.916148 ], dtype=float32),\n",
       " array([-2.1390705,  1.8326213], dtype=float32),\n",
       " array([ 2.0800729, -1.7685606], dtype=float32),\n",
       " array([ 1.6619309, -1.363224 ], dtype=float32),\n",
       " array([ 3.1136556, -2.4372127], dtype=float32),\n",
       " array([ 3.251136, -3.047323], dtype=float32),\n",
       " array([-0.7523026 ,  0.57746255], dtype=float32),\n",
       " array([ 2.791389, -2.625188], dtype=float32),\n",
       " array([ 3.1023097, -2.7217577], dtype=float32),\n",
       " array([ 3.669125 , -3.0038192], dtype=float32),\n",
       " array([ 1.4987675, -0.7775378], dtype=float32),\n",
       " array([-1.8577075,  2.008696 ], dtype=float32),\n",
       " array([ 2.7412257, -2.1241722], dtype=float32),\n",
       " array([ 1.5429217, -1.8607466], dtype=float32),\n",
       " array([ 2.9991534, -2.603775 ], dtype=float32),\n",
       " array([ 3.2582169, -2.62425  ], dtype=float32),\n",
       " array([ 3.087462 , -2.5535595], dtype=float32),\n",
       " array([ 3.3149843, -2.5522583], dtype=float32),\n",
       " array([ 1.928172 , -1.4375381], dtype=float32),\n",
       " array([ 1.9442312, -1.2630652], dtype=float32),\n",
       " array([ 3.128311 , -2.6298501], dtype=float32),\n",
       " array([ 2.843894, -2.764935], dtype=float32),\n",
       " array([ 0.8076776, -0.7854358], dtype=float32),\n",
       " array([ 2.5717869, -2.0829306], dtype=float32),\n",
       " array([ 2.6834226, -2.1872542], dtype=float32),\n",
       " array([ 2.3274179, -1.574429 ], dtype=float32),\n",
       " array([ 2.1180153, -1.7860775], dtype=float32),\n",
       " array([-2.1357925,  1.2544596], dtype=float32),\n",
       " array([-2.0805435,  1.522372 ], dtype=float32),\n",
       " array([ 1.7459654, -1.9298134], dtype=float32),\n",
       " array([ 2.831634, -3.021516], dtype=float32),\n",
       " array([ 2.583375 , -1.7817514], dtype=float32),\n",
       " array([ 2.9397364, -2.5913537], dtype=float32),\n",
       " array([-0.37003687,  0.87451345], dtype=float32),\n",
       " array([ 2.506154, -2.546591], dtype=float32),\n",
       " array([ 2.819713 , -2.6190343], dtype=float32),\n",
       " array([ 3.845457 , -3.3508399], dtype=float32),\n",
       " array([ 3.2936678, -2.4521396], dtype=float32),\n",
       " array([ 2.5340366, -2.4607365], dtype=float32),\n",
       " array([ 3.4555614, -2.6694973], dtype=float32),\n",
       " array([-1.3999912,  1.0665836], dtype=float32),\n",
       " array([-1.1972052,  1.4363694], dtype=float32),\n",
       " array([-2.4653044,  2.0128078], dtype=float32),\n",
       " array([-1.1783074 ,  0.80954474], dtype=float32),\n",
       " array([ 2.6008704, -2.549521 ], dtype=float32),\n",
       " array([-0.7326815,  0.676084 ], dtype=float32),\n",
       " array([ 3.1352987, -2.4194589], dtype=float32),\n",
       " array([ 1.0867659, -0.8333971], dtype=float32),\n",
       " array([-2.5056458,  2.1968431], dtype=float32),\n",
       " array([ 1.2224699, -1.2814189], dtype=float32),\n",
       " array([ 2.557352 , -2.0710506], dtype=float32),\n",
       " array([ 3.4170434, -2.3686502], dtype=float32),\n",
       " array([ 1.2321295, -1.067653 ], dtype=float32),\n",
       " array([ 3.2188907, -2.419235 ], dtype=float32),\n",
       " array([ 0.3153143 , -0.01234502], dtype=float32),\n",
       " array([ 2.8286266, -2.2746847], dtype=float32),\n",
       " array([-1.1689318,  0.9544691], dtype=float32),\n",
       " array([ 2.1390262, -1.8967307], dtype=float32),\n",
       " array([ 3.144557 , -2.9225624], dtype=float32),\n",
       " array([-1.2843692,  1.1321921], dtype=float32),\n",
       " array([ 1.6587665, -1.4441612], dtype=float32),\n",
       " array([ 2.4176817, -2.8484895], dtype=float32),\n",
       " array([ 3.2711725, -2.7396333], dtype=float32),\n",
       " array([ 3.5072172, -2.3941255], dtype=float32),\n",
       " array([ 0.9951252 , -0.42617995], dtype=float32),\n",
       " array([ 3.495636 , -2.3705542], dtype=float32),\n",
       " array([ 2.4016976, -1.8985206], dtype=float32),\n",
       " array([ 3.4221983, -2.9264042], dtype=float32),\n",
       " array([ 1.874122, -1.657027], dtype=float32),\n",
       " array([ 3.4536622, -2.6876318], dtype=float32),\n",
       " array([ 2.8027549, -1.960551 ], dtype=float32),\n",
       " array([ 2.9563246, -2.2093613], dtype=float32),\n",
       " array([ 3.6656265, -2.8495486], dtype=float32),\n",
       " array([ 3.8421655, -3.446123 ], dtype=float32),\n",
       " array([ 3.3434072, -2.6558344], dtype=float32),\n",
       " array([ 2.9539013, -2.3515334], dtype=float32),\n",
       " array([ 3.4303083, -2.681584 ], dtype=float32),\n",
       " array([ 0.6123188 , -0.34495395], dtype=float32),\n",
       " array([ 2.887733, -2.417967], dtype=float32),\n",
       " array([ 2.9499745, -2.7420459], dtype=float32),\n",
       " array([ 2.9978216, -3.0150523], dtype=float32),\n",
       " array([ 3.273946, -2.581374], dtype=float32),\n",
       " array([ 3.5953307, -2.7335732], dtype=float32),\n",
       " array([ 4.0567966, -3.25433  ], dtype=float32),\n",
       " array([ 3.9017673, -3.5442078], dtype=float32),\n",
       " array([-1.4122609,  1.5246468], dtype=float32),\n",
       " array([-2.2709827,  1.8135164], dtype=float32),\n",
       " array([-0.75249976,  0.96135926], dtype=float32),\n",
       " array([-1.078563 ,  1.2377776], dtype=float32),\n",
       " array([ 0.873924 , -0.8660914], dtype=float32),\n",
       " array([ 1.2110656, -1.4861255], dtype=float32),\n",
       " array([ 0.11068954, -0.04705915], dtype=float32),\n",
       " array([ 2.4689255, -2.4377637], dtype=float32),\n",
       " array([ 1.046316 , -0.5277844], dtype=float32),\n",
       " array([ 2.5553927, -2.5003946], dtype=float32),\n",
       " array([ 2.9329672, -2.3147361], dtype=float32),\n",
       " array([ 2.7215605, -1.7853366], dtype=float32),\n",
       " array([ 2.882855 , -2.6428916], dtype=float32),\n",
       " array([ 2.0864902, -1.6901433], dtype=float32),\n",
       " array([ 2.2442641, -2.1418557], dtype=float32),\n",
       " array([ 2.6559563, -1.7956742], dtype=float32),\n",
       " array([ 1.9316906, -1.9855502], dtype=float32),\n",
       " array([ 2.9111216, -2.6913106], dtype=float32),\n",
       " array([ 2.2543817, -1.7297381], dtype=float32),\n",
       " array([ 2.149528 , -1.5087428], dtype=float32),\n",
       " array([ 3.0455399, -2.663612 ], dtype=float32),\n",
       " array([ 2.6639736, -2.4760334], dtype=float32),\n",
       " array([-0.43777028,  0.9423939 ], dtype=float32),\n",
       " array([ 1.5507106, -1.5986178], dtype=float32),\n",
       " array([ 3.0068133, -3.197401 ], dtype=float32),\n",
       " array([ 0.87520105, -0.91990656], dtype=float32),\n",
       " array([-2.5538094,  2.5346444], dtype=float32),\n",
       " array([ 2.1531029, -1.8229876], dtype=float32),\n",
       " array([ 0.3986082, -0.358078 ], dtype=float32),\n",
       " array([ 1.1598053 , -0.96287113], dtype=float32),\n",
       " array([ 2.7973096, -2.5126412], dtype=float32),\n",
       " array([ 1.9273368, -2.2743561], dtype=float32),\n",
       " array([0.25674593, 0.07664856], dtype=float32),\n",
       " array([ 1.8345345, -1.680254 ], dtype=float32),\n",
       " array([ 2.863346 , -2.1364405], dtype=float32),\n",
       " array([ 2.0527525, -2.5444362], dtype=float32),\n",
       " array([ 1.1199802 , -0.70982087], dtype=float32),\n",
       " array([ 2.4683056, -2.1009445], dtype=float32),\n",
       " array([ 1.2348168, -0.951836 ], dtype=float32),\n",
       " array([ 2.3698916, -1.9826715], dtype=float32),\n",
       " array([ 1.624596, -1.282113], dtype=float32),\n",
       " array([ 3.0738893, -2.8689182], dtype=float32),\n",
       " array([ 2.2470074, -1.8905168], dtype=float32),\n",
       " array([ 3.3593502, -2.3481166], dtype=float32),\n",
       " array([ 2.2709627, -1.646714 ], dtype=float32),\n",
       " array([ 1.9446446, -1.3891997], dtype=float32),\n",
       " array([ 2.2192922, -1.4686774], dtype=float32),\n",
       " array([0.41564378, 0.03575545], dtype=float32),\n",
       " array([ 0.8976874, -0.2507873], dtype=float32),\n",
       " array([-0.18749535,  0.26322806], dtype=float32),\n",
       " array([-0.14033844,  0.185889  ], dtype=float32),\n",
       " array([ 1.4598645, -1.3804439], dtype=float32),\n",
       " array([ 1.9349452, -1.6971266], dtype=float32),\n",
       " array([ 2.2641065, -1.9005327], dtype=float32),\n",
       " array([ 2.0973682, -1.998435 ], dtype=float32),\n",
       " array([ 1.665241 , -1.2804124], dtype=float32),\n",
       " array([ 1.0742567 , -0.69312036], dtype=float32),\n",
       " array([ 3.3574376, -3.3860168], dtype=float32),\n",
       " array([ 2.0153217, -1.6753819], dtype=float32),\n",
       " array([ 3.1231608, -2.6110494], dtype=float32),\n",
       " array([ 2.6460595, -1.8376753], dtype=float32),\n",
       " array([ 1.1462249 , -0.79066294], dtype=float32),\n",
       " array([ 2.9025993, -2.9246042], dtype=float32),\n",
       " array([ 0.8677331, -1.059124 ], dtype=float32),\n",
       " array([ 2.1135035, -2.0185866], dtype=float32),\n",
       " array([ 3.1741328, -2.730633 ], dtype=float32),\n",
       " array([-1.9420575,  1.835805 ], dtype=float32),\n",
       " array([-2.3165648,  2.0743754], dtype=float32),\n",
       " array([-2.9202316,  2.2292995], dtype=float32),\n",
       " array([ 1.5093106, -1.6314793], dtype=float32),\n",
       " array([ 1.0200015 , -0.95257753], dtype=float32),\n",
       " array([0.23479164, 0.10654376], dtype=float32),\n",
       " array([ 2.3610806, -2.2214086], dtype=float32),\n",
       " array([ 3.4891562, -2.809313 ], dtype=float32),\n",
       " array([ 2.0293667, -1.7170734], dtype=float32),\n",
       " array([ 3.6482813, -2.50199  ], dtype=float32),\n",
       " array([ 3.1941638, -3.194339 ], dtype=float32),\n",
       " array([-0.43707407,  0.75073147], dtype=float32),\n",
       " array([-1.2781988,  1.6656957], dtype=float32),\n",
       " array([-1.8149266,  1.5273496], dtype=float32),\n",
       " array([-2.006785 ,  2.1736658], dtype=float32),\n",
       " array([ 0.24243438, -0.39707422], dtype=float32),\n",
       " array([ 2.8632362, -2.190635 ], dtype=float32),\n",
       " array([ 2.8313012, -2.3142214], dtype=float32),\n",
       " array([-1.5149326,  1.6558565], dtype=float32),\n",
       " array([-0.32330242,  0.35961664], dtype=float32),\n",
       " array([ 2.7184591, -2.3040485], dtype=float32),\n",
       " array([ 3.0905638, -3.0830247], dtype=float32),\n",
       " array([ 2.096933 , -1.8342614], dtype=float32),\n",
       " array([ 2.6028295, -2.248926 ], dtype=float32),\n",
       " array([ 3.2058747, -3.0868022], dtype=float32),\n",
       " array([ 3.4974945, -3.3321419], dtype=float32),\n",
       " array([ 2.9427729, -2.8741405], dtype=float32),\n",
       " array([-0.19509867,  0.4395482 ], dtype=float32),\n",
       " array([ 2.9991322, -2.5818868], dtype=float32),\n",
       " array([-1.090036,  1.076937], dtype=float32),\n",
       " array([ 2.953346, -2.290294], dtype=float32),\n",
       " array([ 2.764729, -2.323284], dtype=float32),\n",
       " array([ 3.3012471, -2.3602164], dtype=float32),\n",
       " array([ 3.7124763, -2.6886632], dtype=float32),\n",
       " array([ 2.692007 , -2.4263544], dtype=float32),\n",
       " array([-0.18483278,  0.14588922], dtype=float32),\n",
       " array([ 2.1801405, -2.1671317], dtype=float32),\n",
       " array([ 1.9644507, -1.6944058], dtype=float32),\n",
       " array([ 2.9484859, -2.4555454], dtype=float32),\n",
       " array([ 3.2086954, -2.722812 ], dtype=float32),\n",
       " array([ 2.530952 , -2.4972668], dtype=float32),\n",
       " array([ 2.588439 , -1.9773026], dtype=float32),\n",
       " array([ 2.589319, -1.970861], dtype=float32),\n",
       " array([ 1.2926121, -1.530535 ], dtype=float32),\n",
       " array([ 2.3280025, -2.15732  ], dtype=float32),\n",
       " array([ 3.4176142, -2.7977896], dtype=float32),\n",
       " array([ 3.0887353, -2.1146035], dtype=float32),\n",
       " array([ 1.2266301, -0.7365038], dtype=float32),\n",
       " array([-1.0026118,  1.3367169], dtype=float32),\n",
       " array([ 3.1602926, -3.1145427], dtype=float32),\n",
       " array([ 3.114191 , -3.0158746], dtype=float32),\n",
       " array([ 2.983941 , -3.1498446], dtype=float32),\n",
       " array([ 3.5578346, -2.9871733], dtype=float32),\n",
       " array([ 3.225911 , -2.7909827], dtype=float32),\n",
       " array([ 3.1495132, -3.0413163], dtype=float32),\n",
       " array([ 2.6152163, -2.069545 ], dtype=float32),\n",
       " array([ 2.6125536, -2.0907943], dtype=float32),\n",
       " array([ 2.6618967, -2.2286124], dtype=float32),\n",
       " array([ 1.3676591, -1.2208772], dtype=float32),\n",
       " array([ 2.7603273, -2.9610126], dtype=float32),\n",
       " array([ 3.2175415, -2.798175 ], dtype=float32),\n",
       " array([0.1862662 , 0.02572083], dtype=float32),\n",
       " array([ 1.762722 , -1.4173895], dtype=float32),\n",
       " array([ 3.4705477, -2.7334778], dtype=float32),\n",
       " array([ 2.8583531, -2.7605846], dtype=float32),\n",
       " array([ 3.3474226, -2.8606575], dtype=float32),\n",
       " array([ 2.2511528, -2.0026417], dtype=float32),\n",
       " array([-1.2039851 ,  0.84781104], dtype=float32),\n",
       " array([ 2.5482764, -2.0926535], dtype=float32),\n",
       " array([ 2.1163769, -2.3926384], dtype=float32),\n",
       " array([ 0.28228107, -0.43505156], dtype=float32),\n",
       " array([ 2.8259125, -2.058811 ], dtype=float32),\n",
       " array([ 2.316888, -2.236232], dtype=float32),\n",
       " array([ 2.5346782, -2.809375 ], dtype=float32),\n",
       " array([ 2.7349184, -3.2021537], dtype=float32),\n",
       " array([ 1.9845518, -2.228809 ], dtype=float32),\n",
       " array([ 1.0083052, -0.7488961], dtype=float32),\n",
       " array([ 3.4862106, -2.855161 ], dtype=float32),\n",
       " array([ 3.1471903, -2.814625 ], dtype=float32),\n",
       " array([ 2.1846385, -1.831115 ], dtype=float32),\n",
       " array([ 1.6956354, -1.0500327], dtype=float32),\n",
       " array([-2.040469 ,  1.8588941], dtype=float32),\n",
       " array([ 2.234972, -2.526878], dtype=float32),\n",
       " array([ 3.2366483, -2.7151237], dtype=float32),\n",
       " array([ 1.2991203, -1.4461322], dtype=float32),\n",
       " array([ 2.8531985, -2.11631  ], dtype=float32),\n",
       " array([ 2.76796 , -2.401963], dtype=float32),\n",
       " array([ 2.0311909, -2.0457227], dtype=float32),\n",
       " array([ 2.6774178, -1.9635494], dtype=float32),\n",
       " array([ 3.0481308, -2.2596304], dtype=float32),\n",
       " array([ 1.7985955, -1.2522857], dtype=float32),\n",
       " array([ 1.7879785, -1.4837024], dtype=float32),\n",
       " array([ 3.5905726, -2.805507 ], dtype=float32),\n",
       " array([ 3.3274064, -2.5451047], dtype=float32),\n",
       " array([ 2.534213 , -2.2237825], dtype=float32),\n",
       " array([-1.5996403,  1.7072003], dtype=float32),\n",
       " array([ 1.3992571, -1.2343321], dtype=float32),\n",
       " array([ 2.9203048, -2.986714 ], dtype=float32),\n",
       " array([ 1.91598  , -1.4264035], dtype=float32),\n",
       " array([ 2.635501 , -2.3354342], dtype=float32),\n",
       " array([ 2.9894078, -2.5437162], dtype=float32),\n",
       " array([ 2.33859  , -2.1170936], dtype=float32),\n",
       " array([ 1.7247862, -1.3219254], dtype=float32),\n",
       " array([ 1.9153255, -1.482261 ], dtype=float32),\n",
       " array([ 2.2438426, -2.040936 ], dtype=float32),\n",
       " array([ 2.5433908, -2.0188437], dtype=float32),\n",
       " array([ 1.643992 , -1.1631185], dtype=float32),\n",
       " array([ 2.124358 , -1.8535476], dtype=float32),\n",
       " array([ 2.1100059, -1.6557654], dtype=float32),\n",
       " array([ 3.2092986, -2.5251696], dtype=float32),\n",
       " array([ 2.8653574, -2.0984077], dtype=float32),\n",
       " array([ 1.8827797, -1.1991584], dtype=float32),\n",
       " array([ 2.663805, -2.198326], dtype=float32),\n",
       " array([ 2.0414793, -1.9782507], dtype=float32),\n",
       " array([ 2.7623954, -1.6193011], dtype=float32),\n",
       " array([ 2.291263 , -1.7691257], dtype=float32),\n",
       " array([ 2.3330078, -2.1212604], dtype=float32),\n",
       " array([ 2.6382408, -2.082461 ], dtype=float32),\n",
       " array([ 1.6671971, -1.8196042], dtype=float32),\n",
       " array([ 3.9751968, -3.4441423], dtype=float32),\n",
       " array([ 1.3096535 , -0.70923775], dtype=float32),\n",
       " array([ 2.7482948, -2.3646896], dtype=float32),\n",
       " array([ 1.9456209, -1.5888008], dtype=float32),\n",
       " array([ 2.7852578, -2.0953734], dtype=float32),\n",
       " array([ 2.453469 , -2.0263216], dtype=float32),\n",
       " array([-1.6036083,  1.7131026], dtype=float32),\n",
       " array([ 2.241232 , -1.7458377], dtype=float32),\n",
       " array([ 0.80330527, -0.7879705 ], dtype=float32),\n",
       " array([ 2.6112347, -2.6265683], dtype=float32),\n",
       " array([ 2.5666566, -2.3234105], dtype=float32),\n",
       " array([-1.5127496,  1.5216254], dtype=float32),\n",
       " array([ 1.0287524, -1.1091235], dtype=float32),\n",
       " array([ 1.4765087, -1.7104259], dtype=float32),\n",
       " array([ 2.0496426, -1.6664872], dtype=float32),\n",
       " array([ 2.1479666, -2.523911 ], dtype=float32),\n",
       " array([ 2.9764714, -2.0929925], dtype=float32),\n",
       " array([ 0.8485143, -0.8721048], dtype=float32),\n",
       " array([ 0.69685996, -0.37911004], dtype=float32),\n",
       " array([ 2.963159 , -2.6764154], dtype=float32),\n",
       " array([ 2.1534235, -1.4340404], dtype=float32),\n",
       " array([ 2.6411433, -2.5870516], dtype=float32),\n",
       " array([ 1.4177619, -1.2722577], dtype=float32),\n",
       " array([ 2.5744934, -2.7651818], dtype=float32),\n",
       " array([ 1.6080028, -1.1924298], dtype=float32),\n",
       " array([ 1.7098377, -1.3263191], dtype=float32),\n",
       " array([ 3.0555947, -2.1593404], dtype=float32),\n",
       " array([ 1.4214036, -0.8903967], dtype=float32),\n",
       " array([ 2.3681657, -1.9732616], dtype=float32),\n",
       " array([ 3.4528394, -2.941973 ], dtype=float32),\n",
       " array([ 1.5610241, -1.6623846], dtype=float32),\n",
       " array([ 1.5346092, -1.4214416], dtype=float32),\n",
       " array([ 3.1653395, -2.7169578], dtype=float32),\n",
       " array([ 2.6020675, -2.087217 ], dtype=float32),\n",
       " array([ 3.3733273, -2.355609 ], dtype=float32),\n",
       " array([ 2.1866293, -2.016876 ], dtype=float32),\n",
       " array([-1.1548775 ,  0.91964436], dtype=float32),\n",
       " array([ 2.8888116, -2.6270974], dtype=float32),\n",
       " array([ 2.43609  , -2.2317407], dtype=float32),\n",
       " array([ 0.93060064, -0.821837  ], dtype=float32),\n",
       " array([ 2.105876 , -1.9306993], dtype=float32),\n",
       " array([ 2.4086049, -1.9396951], dtype=float32),\n",
       " array([ 2.873413 , -2.2028415], dtype=float32),\n",
       " array([ 3.2958982, -2.9377553], dtype=float32),\n",
       " array([ 2.4746761, -2.054618 ], dtype=float32),\n",
       " array([ 2.7111444, -2.4846857], dtype=float32),\n",
       " array([ 2.077374 , -1.6904955], dtype=float32),\n",
       " array([ 3.2521312, -2.7839997], dtype=float32),\n",
       " array([ 1.362825 , -0.7714784], dtype=float32),\n",
       " array([ 2.6965227, -2.6297963], dtype=float32),\n",
       " array([ 2.2948048, -2.573713 ], dtype=float32),\n",
       " array([-1.5622233,  1.7683809], dtype=float32),\n",
       " array([ 1.8959574, -1.6147135], dtype=float32),\n",
       " array([-0.11091535,  0.23936337], dtype=float32),\n",
       " array([ 2.543406 , -2.1955163], dtype=float32),\n",
       " array([ 1.7389807, -1.809551 ], dtype=float32),\n",
       " array([ 3.1603642, -2.5261595], dtype=float32),\n",
       " array([ 2.5832522, -2.3987896], dtype=float32),\n",
       " array([ 2.509719, -2.291361], dtype=float32),\n",
       " array([ 2.8703814, -1.886244 ], dtype=float32),\n",
       " array([ 1.6649619, -1.1499513], dtype=float32),\n",
       " array([-1.0097294 ,  0.68845254], dtype=float32),\n",
       " array([ 3.329108 , -2.9079807], dtype=float32),\n",
       " array([ 1.9809657, -2.057198 ], dtype=float32),\n",
       " array([ 3.1216886, -2.7511747], dtype=float32),\n",
       " array([ 2.8816946, -2.2404883], dtype=float32),\n",
       " array([ 2.5557995, -1.9568641], dtype=float32),\n",
       " array([-0.24690413,  0.9559592 ], dtype=float32),\n",
       " array([-1.675151 ,  1.0707333], dtype=float32),\n",
       " array([-1.8506213,  1.9255406], dtype=float32),\n",
       " array([-0.24586856, -0.01043886], dtype=float32),\n",
       " array([ 2.6854033, -2.8679533], dtype=float32),\n",
       " array([ 2.475809, -2.382981], dtype=float32),\n",
       " array([ 1.939081 , -1.3253305], dtype=float32),\n",
       " array([ 3.0475662, -2.7774222], dtype=float32),\n",
       " array([ 1.0212474, -1.26408  ], dtype=float32),\n",
       " array([ 1.811201 , -1.5785022], dtype=float32),\n",
       " array([-0.595442  ,  0.66706246], dtype=float32),\n",
       " array([-0.17828602,  0.4127363 ], dtype=float32),\n",
       " array([ 2.339493 , -2.5319793], dtype=float32),\n",
       " array([ 1.7937051, -1.6893768], dtype=float32),\n",
       " array([-0.95968914,  1.0731225 ], dtype=float32),\n",
       " array([ 2.7345624, -2.3190045], dtype=float32),\n",
       " array([ 3.053814, -2.540305], dtype=float32),\n",
       " array([ 1.3101956, -1.4984651], dtype=float32),\n",
       " array([ 2.5959916, -2.769224 ], dtype=float32),\n",
       " array([ 2.3374734, -1.7166202], dtype=float32),\n",
       " array([-1.039318  ,  0.86826485], dtype=float32),\n",
       " array([ 3.0471692, -2.7833536], dtype=float32),\n",
       " array([ 1.1449913 , -0.93724275], dtype=float32),\n",
       " array([ 1.2677704, -1.4548311], dtype=float32),\n",
       " array([ 3.4496968, -2.569368 ], dtype=float32),\n",
       " array([ 2.5608985, -1.8928769], dtype=float32),\n",
       " array([ 1.8200579, -1.8755274], dtype=float32),\n",
       " array([ 3.6038346, -2.7960145], dtype=float32),\n",
       " array([ 3.021976 , -2.2953842], dtype=float32),\n",
       " array([ 0.71247196, -0.23748708], dtype=float32),\n",
       " array([ 2.3122158, -2.07422  ], dtype=float32),\n",
       " array([ 2.0880513, -1.4690838], dtype=float32),\n",
       " array([-1.0130193,  0.7098968], dtype=float32),\n",
       " array([ 2.2999167, -2.0982454], dtype=float32),\n",
       " array([ 2.8372731, -2.2884562], dtype=float32),\n",
       " array([ 2.4716744, -2.3399823], dtype=float32),\n",
       " array([ 2.8234863, -2.2951996], dtype=float32),\n",
       " array([ 2.3399463, -2.3117287], dtype=float32),\n",
       " array([ 1.9484423, -1.6893632], dtype=float32),\n",
       " array([ 1.9830498, -1.6339645], dtype=float32),\n",
       " array([ 1.8393687, -1.4760963], dtype=float32),\n",
       " array([ 2.9871755, -2.746102 ], dtype=float32),\n",
       " array([ 2.3159015, -1.8521318], dtype=float32),\n",
       " array([-1.4813675,  1.9669323], dtype=float32),\n",
       " array([ 1.6142048, -1.5272572], dtype=float32),\n",
       " array([-0.9423387,  0.6156243], dtype=float32),\n",
       " array([ 1.709956 , -1.5763588], dtype=float32),\n",
       " array([ 0.8264953, -0.7772982], dtype=float32),\n",
       " array([ 1.7017049, -1.537214 ], dtype=float32),\n",
       " array([ 1.2947365, -1.268945 ], dtype=float32),\n",
       " array([ 2.7277536, -2.6068966], dtype=float32),\n",
       " array([ 1.1806843, -0.8393862], dtype=float32),\n",
       " array([ 2.2046952, -2.098714 ], dtype=float32),\n",
       " array([-0.7752651,  0.5504092], dtype=float32),\n",
       " array([ 0.9840306 , -0.89887536], dtype=float32),\n",
       " array([ 2.3649056, -1.8822781], dtype=float32),\n",
       " array([ 2.0110545, -2.2797756], dtype=float32),\n",
       " array([ 1.7163723, -1.725173 ], dtype=float32),\n",
       " array([ 0.11646798, -0.31289953], dtype=float32),\n",
       " array([ 1.8072933, -1.8180718], dtype=float32),\n",
       " array([ 0.6422386, -0.463097 ], dtype=float32),\n",
       " array([ 0.615129  , -0.53238416], dtype=float32),\n",
       " array([ 1.9439881, -1.9463692], dtype=float32),\n",
       " array([-1.3153499,  1.492337 ], dtype=float32),\n",
       " array([ 2.3810253, -2.258608 ], dtype=float32),\n",
       " array([-0.51461464,  0.7254864 ], dtype=float32),\n",
       " array([ 2.538198 , -2.4223468], dtype=float32),\n",
       " array([ 2.824144, -2.808757], dtype=float32),\n",
       " array([ 3.9215903, -2.8277957], dtype=float32),\n",
       " array([ 3.3458936, -2.984928 ], dtype=float32),\n",
       " array([ 2.2160811, -1.7412639], dtype=float32),\n",
       " array([ 3.0722113, -2.3121002], dtype=float32),\n",
       " array([ 3.4123368, -2.7322338], dtype=float32),\n",
       " array([ 3.5299568, -2.9715827], dtype=float32),\n",
       " array([ 2.7424102, -2.7254035], dtype=float32),\n",
       " array([ 3.8925757, -3.0173376], dtype=float32),\n",
       " array([ 1.5637704, -1.8555956], dtype=float32),\n",
       " array([ 0.63367504, -0.22236627], dtype=float32),\n",
       " array([ 2.898982 , -2.3289535], dtype=float32),\n",
       " array([ 3.1662083, -2.4978893], dtype=float32),\n",
       " array([ 2.3055816, -2.1397345], dtype=float32),\n",
       " array([ 3.5272207, -2.6355488], dtype=float32),\n",
       " ...]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[\"logits\"] for x in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
